{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f993a7bfa30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST(root = './content',\n",
    "                                       train = True,\n",
    "                                       download = False,\n",
    "                                       transform = transforms.ToTensor())\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(root='./content',\n",
    "                                     train = False,\n",
    "                                     download = False,\n",
    "                                     transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./content\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(train_set,\n",
    "                       batch_size = 15,\n",
    "                       shuffle = True,\n",
    "                       num_workers = 4)\n",
    "test_data = DataLoader(test_set,\n",
    "                       batch_size = 15,\n",
    "                       shuffle = True,\n",
    "                       num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28,256, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256,128, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128,64, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64,3, bias=True))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3,64, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64,128, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128,256, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256,28*28, bias=True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "#         x.apply(init_weight_function)\n",
    "#         x.apply(init_batch_function)\n",
    "        x = self.decoder(x)\n",
    "#         x.apply(init_weight_function)\n",
    "#         x.apply(init_batch_function)\n",
    "        return x\n",
    "        \n",
    "    def init_weight_function(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "  \n",
    "    def init_batch_function(self, n):\n",
    "        if isinstance(n, nn.BatchNorm1d):\n",
    "            torch.nn.init.xavier_uniform_(n.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Autoencoder_model = Autoencoder()\n",
    "optimizer = torch.optim.Adam(Autoencoder_model.parameters(),\n",
    "                             lr=0.01,weight_decay=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Autoencoder_model(torch.FloatTensor(15,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = [1/20], loss = 0.0421\n",
      "epoch = [2/20], loss = 0.0526\n",
      "epoch = [3/20], loss = 0.0517\n",
      "epoch = [4/20], loss = 0.0513\n",
      "epoch = [5/20], loss = 0.0464\n",
      "epoch = [6/20], loss = 0.0454\n",
      "epoch = [7/20], loss = 0.0498\n",
      "epoch = [8/20], loss = 0.0520\n",
      "epoch = [9/20], loss = 0.0526\n",
      "epoch = [10/20], loss = 0.0410\n",
      "epoch = [11/20], loss = 0.0524\n",
      "epoch = [12/20], loss = 0.0552\n",
      "epoch = [13/20], loss = 0.0524\n",
      "epoch = [14/20], loss = 0.0480\n",
      "epoch = [15/20], loss = 0.0486\n",
      "epoch = [16/20], loss = 0.0470\n",
      "epoch = [17/20], loss = 0.0452\n",
      "epoch = [18/20], loss = 0.0439\n",
      "epoch = [19/20], loss = 0.0580\n",
      "epoch = [20/20], loss = 0.0492\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "loss_data = []\n",
    "collect_img = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    for data in train_data:\n",
    "        img_data, _ = data\n",
    "        img_data = img_data.view(img_data.size(0),-1)\n",
    "#         img_data = Variable(img_data)\n",
    "\n",
    "        output = Autoencoder_model(img_data)\n",
    "        loss = criterion(output, img_data)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('epoch = [{}/{}], loss = {:.4f}'.format(i+1,epochs,loss.item()))\n",
    "    loss_data.append(loss.item)\n",
    "    pic = to_img(output.cpu().data)\n",
    "    collect_img.append(pic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
