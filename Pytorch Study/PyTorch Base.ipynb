{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이토치(PyTorch)\n",
    "- 코드 출처 : https://pytorch.org/tutorials/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이토치의 구성 요소\n",
    "- torch : 텐서를 생성하는 라이브러리\n",
    "- torch.autograd : 자동 미분 기능을 제공하는 라이브러리\n",
    "- torch.nn : 신경망을 생성하는 라이브러리\n",
    "- torch.multiprocessing : 병렬처리 기능을 제공하는 라이브러리\n",
    "- torch.utils : 데이터 조작 등 유틸리티 기능 제공\n",
    "- torch.legacy(./nn/.optim) : Torch로부터 포팅해온 코드\n",
    "- torch.onnx : ONNX(Open Neural Network Exchange)\n",
    "    - 서로 다른 프레임워크 간의 모델을 공유할 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서(Tensors)\n",
    "- 넘파이(Numpy)의 ndarray와 유사\n",
    "- GPU를 사용한 연산 가속도 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 초기화 되지 않은 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.6928e+16, 4.5831e-41],\n",
      "        [9.6094e+16, 4.5831e-41],\n",
      "        [0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(4,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 무작위로 초기화된 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9514, 0.4839],\n",
      "        [0.8783, 0.1085],\n",
      "        [0.6706, 0.3788],\n",
      "        [0.0761, 0.2097]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dtype이 long, 0으로 채워진 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(4,2,dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0000, 2.3000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([3, 2.3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(2,4,dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0071, -0.0937,  0.4996, -0.7206],\n",
      "        [-1.1112,  0.7797,  2.2502, -0.1907]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서의 연산(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 덧셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0071, -0.0937,  0.4996, -0.7206],\n",
      "        [-1.1112,  0.7797,  2.2502, -0.1907]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0793, 0.3882, 0.7453, 0.5012],\n",
      "        [0.8574, 0.5236, 0.7108, 0.1687]])\n",
      "tensor([[ 0.0864,  0.2945,  1.2449, -0.2194],\n",
      "        [-0.2538,  1.3033,  2.9610, -0.0220]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(2,4)\n",
    "print(y)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0864,  0.2945,  1.2449, -0.2194],\n",
      "        [-0.2538,  1.3033,  2.9610, -0.0220]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0864,  0.2945,  1.2449, -0.2194],\n",
      "        [-0.2538,  1.3033,  2.9610, -0.0220]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(2,4)\n",
    "torch.add(x,y,out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0071, -0.0937,  0.4996, -0.7206],\n",
      "        [-1.1112,  0.7797,  2.2502, -0.1907]])\n",
      "tensor([[ 0.1075,  0.0134,  2.7438, -2.3811],\n",
      "        [-3.5874,  3.6424,  9.7117, -0.5941]])\n",
      "tensor([[ 0.1146, -0.0803,  3.2434, -3.1017],\n",
      "        [-4.6986,  4.4221, 11.9620, -0.7848]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "y.add_(x) # y+=x\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 뺄셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1.],\n",
      "        [-1., -1.]])\n",
      "tensor([[-1., -1.],\n",
      "        [-1., -1.]])\n",
      "tensor([[-1., -1.],\n",
      "        [-1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,3],\n",
    "                 [5,7]])\n",
    "y = torch.Tensor([[2,4],\n",
    "                  [6,8]])\n",
    "print(x - y)\n",
    "print(torch.sub(x,y))\n",
    "print(x.sub(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 곱셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2., 12.],\n",
      "        [30., 56.]])\n",
      "tensor([[ 2., 12.],\n",
      "        [30., 56.]])\n",
      "tensor([[ 2., 12.],\n",
      "        [30., 56.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,3],\n",
    "                 [5,7]])\n",
    "y = torch.Tensor([[2,4],\n",
    "                  [6,8]])\n",
    "print(x * y)\n",
    "print(torch.mul(x,y))\n",
    "print(x.mul(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나눗셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.7500],\n",
      "        [0.8333, 0.8750]])\n",
      "tensor([[0.5000, 0.7500],\n",
      "        [0.8333, 0.8750]])\n",
      "tensor([[0.5000, 0.7500],\n",
      "        [0.8333, 0.8750]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,3],\n",
    "                 [5,7]])\n",
    "y = torch.Tensor([[2,4],\n",
    "                  [6,8]])\n",
    "print(x/ y)\n",
    "print(torch.div(x,y))\n",
    "print(x.div(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dot 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20., 28.],\n",
      "        [52., 76.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,3],\n",
    "                 [5,7]])\n",
    "y = torch.Tensor([[2,4],\n",
    "                  [6,8]])\n",
    "print(torch.mm(x,y))\n",
    "#행렬곱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서의 조작(manipulations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인덱싱\n",
    "- 넘파이처럼 인덱싱 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 3.],\n",
      "        [5., 7.]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "print(x[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view\n",
    "- 텐서의 크기(size)나 모양(shape)을 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1284, -0.5241, -0.1175,  0.4338, -1.0532],\n",
      "        [ 0.4988,  0.6994,  0.4140,  0.1769, -1.7826],\n",
      "        [-0.7610,  0.4686, -0.8459,  1.3099,  1.2445],\n",
      "        [-0.7386,  0.4788, -1.5141, -1.1108, -0.1658]])\n",
      "torch.Size([4, 5])\n",
      "------------------------------\n",
      "tensor([ 1.1284, -0.5241, -0.1175,  0.4338, -1.0532,  0.4988,  0.6994,  0.4140,\n",
      "         0.1769, -1.7826, -0.7610,  0.4686, -0.8459,  1.3099,  1.2445, -0.7386,\n",
      "         0.4788, -1.5141, -1.1108, -0.1658])\n",
      "torch.Size([20])\n",
      "------------------------------\n",
      "tensor([[ 1.1284, -0.5241, -0.1175,  0.4338],\n",
      "        [-1.0532,  0.4988,  0.6994,  0.4140],\n",
      "        [ 0.1769, -1.7826, -0.7610,  0.4686],\n",
      "        [-0.8459,  1.3099,  1.2445, -0.7386],\n",
      "        [ 0.4788, -1.5141, -1.1108, -0.1658]])\n",
      "torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,5)\n",
    "y = x.view(20)\n",
    "z = x.view(5,-1)\n",
    "print(x)\n",
    "print(x.size())\n",
    "print('-'*30)\n",
    "print(y)\n",
    "print(y.size())\n",
    "print('-'*30)\n",
    "print(z)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item\n",
    "- 텐서에 값이 단 하나라도 존재하면 숫자값을 얻을 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4178])\n",
      "-1.4177613258361816\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 스칼라값 하나만 존재해야합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6971, -1.4061])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-6e50ec3050e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#only one element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2) #only one element\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squeez\n",
    "- 차원을 축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7596, 0.4209, 0.9759],\n",
      "         [0.5546, 0.8425, 0.2941],\n",
      "         [0.0380, 0.3146, 0.1152]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(1,3,3)\n",
    "print(tensor)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7596, 0.4209, 0.9759],\n",
      "        [0.5546, 0.8425, 0.2941],\n",
      "        [0.0380, 0.3146, 0.1152]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "t = tensor.squeeze()\n",
    "\n",
    "print(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unsqueeze\n",
    "- 차원을 증가(생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9203, 0.6863, 0.8793],\n",
      "         [0.4549, 0.7814, 0.3025],\n",
      "         [0.2959, 0.8701, 0.3776]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(1,3,3)\n",
    "print(tensor)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.9203, 0.6863, 0.8793],\n",
      "          [0.4549, 0.7814, 0.3025],\n",
      "          [0.2959, 0.8701, 0.3776]]]])\n",
      "torch.Size([1, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "t = tensor.unsqueeze(dim=0)\n",
    "\n",
    "print(t)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stack\n",
    "-텐서간 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([1,4])\n",
    "y = torch.FloatTensor([2,5])\n",
    "z = torch.FloatTensor([3,6])\n",
    "\n",
    "print(torch.stack([x,y,z]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cat\n",
    "- 텐서들 결합하는 메소드(concatenate)\n",
    "- 넘파이의 stack과 유사하지만, 쌓을 dim이 존재해야함\n",
    "    - 예를들어 해당 차원을 늘려준 후 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.0258,  0.2413,  0.0436],\n",
      "          [-1.8215, -1.5626,  0.1262],\n",
      "          [ 0.6865,  0.6094,  0.1325]]],\n",
      "\n",
      "\n",
      "        [[[-0.5231,  0.7969,  0.5752],\n",
      "          [-0.4449, -1.1408,  0.7321],\n",
      "          [-1.9489, -0.6903, -0.0968]]]])\n",
      "torch.Size([2, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,1,3,3)\n",
    "b = torch.randn(1,1,3,3)\n",
    "\n",
    "c = torch.cat((a,b),dim=0)\n",
    "\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.8580, -0.3079,  0.4898],\n",
      "         [-0.0914, -1.1819, -0.1145],\n",
      "         [ 0.0660,  0.3166,  1.7925]],\n",
      "\n",
      "        [[-0.2714, -0.8575, -0.9471],\n",
      "         [ 0.6291,  0.1351, -0.8697],\n",
      "         [ 0.9377,  0.6172,  0.2169]]])\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,3)\n",
    "b = torch.randn(1,3,3)\n",
    "\n",
    "c = torch.cat((a,b),dim=0)\n",
    "\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4130,  1.2538,  0.9535],\n",
      "         [-0.6587, -0.7542,  1.0087],\n",
      "         [ 2.9472,  0.2344, -0.3197],\n",
      "         [ 1.2219, -0.0900,  0.3925],\n",
      "         [ 1.6753,  0.6767,  0.0171],\n",
      "         [-0.3969,  0.9053,  1.2831]]])\n",
      "torch.Size([1, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,3)\n",
    "b = torch.randn(1,3,3)\n",
    "\n",
    "c = torch.cat((a,b),dim=1)\n",
    "\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2827, -1.8941,  0.6851,  1.1094,  0.2734, -1.7775],\n",
      "         [-0.1275,  0.3890,  1.1529, -1.9799, -0.7360, -0.7676],\n",
      "         [ 1.4209,  0.3252,  1.3687, -0.0065,  0.7489,  0.0658]]])\n",
      "torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,3)\n",
    "b = torch.randn(1,3,3)\n",
    "\n",
    "c = torch.cat((a,b),dim=2)\n",
    "\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chunk\n",
    "- 텐서를 여러 개로 나눌 때 사용\n",
    "- 몇 개의 텐서로 나눌 것이냐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6186, 0.2993, 0.6407, 0.9264, 0.0302, 0.3762],\n",
      "        [0.8448, 0.9685, 0.9234, 0.5026, 0.6307, 0.7754],\n",
      "        [0.3982, 0.9063, 0.5199, 0.9956, 0.1757, 0.4801]])\n",
      "tensor([[0.6186, 0.2993],\n",
      "        [0.8448, 0.9685],\n",
      "        [0.3982, 0.9063]])\n",
      "tensor([[0.6407, 0.9264],\n",
      "        [0.9234, 0.5026],\n",
      "        [0.5199, 0.9956]])\n",
      "tensor([[0.0302, 0.3762],\n",
      "        [0.6307, 0.7754],\n",
      "        [0.1757, 0.4801]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,6)\n",
    "t1,t2,t3 = torch.chunk(tensor,3,dim=1) #가운데 3의 의미는 3개의 텐서로 나누는 의미\n",
    "\n",
    "print(tensor)\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split\n",
    "- chunk와 동일한 기능이지만 조금 다름\n",
    "- 하나의 텐서당 크기가 얼마이냐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2303, 0.5438, 0.3819, 0.8800, 0.4684, 0.3859],\n",
      "        [0.6558, 0.4083, 0.4016, 0.4859, 0.4613, 0.2415],\n",
      "        [0.6207, 0.4547, 0.7858, 0.9664, 0.8798, 0.8942]])\n",
      "tensor([[0.2303, 0.5438, 0.3819],\n",
      "        [0.6558, 0.4083, 0.4016],\n",
      "        [0.6207, 0.4547, 0.7858]])\n",
      "tensor([[0.8800, 0.4684, 0.3859],\n",
      "        [0.4859, 0.4613, 0.2415],\n",
      "        [0.9664, 0.8798, 0.8942]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,6)\n",
    "t1,t2 = torch.split(tensor,3,dim=1) #가운데 3의 의미는 나뉘어지는 하나의 텐서의 사이즈가 3으로\n",
    "\n",
    "print(tensor)\n",
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch $\\leftrightarrow$ numpy\n",
    " - torch Tensor(텐서)를 Numpy array(배열)로 변환 가능\n",
    "     - numpy()\n",
    "     - from_numpy()\n",
    " - (참고)\n",
    "     - Tensor가 CPU산에 있다면 Numpy 배열은 메모리 공간을 공유하므로 하나가 변하면, 다른 하나도 변함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(7)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(a.add_(1))\n",
    "print(b) #동일한 메모리 차지 텐서 계산하면 넘파이도 변경된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.ones(7)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a,1,out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Tensors\n",
    "- .to 메소드를 사용하여 텐서를 어떠한 장치로도 옮길 수 있음\n",
    "    - 예) cpu,gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8328])\n",
      "0.832764208316803\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "tensor([1.8328])\n",
      "tensor([1.8328], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "y = torch.ones_like(x, device=device)\n",
    "x = x.to(device)\n",
    "z = x+y\n",
    "print(device)\n",
    "print(z)\n",
    "print(z.to('cpu',torch.double))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUTIGRAD(자동미분)\n",
    "- autograd 패키지는 Tensor의 모든 연산에 대해 자동 미분 제공\n",
    "- 이는 코드를 어떻게 작성하여 실행하느냐에 따라 역전파가 정의된다는 뜻\n",
    "- backprop를 위한 미분값을 자동으로 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "- data : tensor 형태의 데이터\n",
    "- grad : data가 거쳐온 layer에 대한 미분값 저장\n",
    "- grad_fn : 미분값을 계산한 함수에 대한 정보 저장(어떤 함수에 대해서 backprop 했는지)\n",
    "- requires_grad 속성을 True로 설정하면, 해당 텐서에서 이루어지는 모든 연산들을 추적하기 시작\n",
    "- 계산이 완료된 후 .backward()를 호출하면 자동으로 gradient를 계산할 수 있으며, .grad 속성에 누적됨\n",
    "- 기록을 추적하는 것을 중단하게 하려면, detach()를 호출하여 연산기록으로부터 분리\n",
    "- 기록을 추적하는 것을 방지하기 위해 코드 블럭을 with torch.no_grad():로 감싸면 gradient는 필요없지만, requires_grad=True로 설정되어 학습 가능한 매개변수를 갖는 모델을 평가(evaluate)할 때 유용\n",
    "- Autograd 구현에서 매우 중요한 클래스 : Function 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3,3,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.],\n",
      "        [6., 6., 6.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x+5\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7fc25c95ec90>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[72., 72., 72.],\n",
      "        [72., 72., 72.],\n",
      "        [72., 72., 72.]], grad_fn=<MulBackward0>) tensor(72., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y*2\n",
    "out = z.mean()\n",
    "\n",
    "print(z,out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- requires_grad_(...)는 기존 텐서의 requires_grad값을 바꿔치기(in-place)하여 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x7fc2600b82d0>\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3,3)\n",
    "a = ((a*3)/(a-1))\n",
    "print(a.requires_grad)\n",
    "\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "\n",
    "b = (a*a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기(Gradient)\n",
    "- 역전파 : .backward()를 통해 역전파 계산 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.6667, 2.6667, 2.6667],\n",
      "        [2.6667, 2.6667, 2.6667],\n",
      "        [2.6667, 2.6667, 2.6667]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-640.6983,  714.8936,  756.7545], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x*2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y*2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1,1.0,0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with torch.no_grad()를 허용하여 gradient의 업데이트를 하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x**2).requires_grad)\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- detach() : 내용물은 같지만 requires_grad가 다른 새로운 텐서를 가져올 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "y = x.detach()\n",
    "print(y.requires_grad)\n",
    "print(x.eq(y).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자동 미분 흐름 다시 보기(1)\n",
    "- 계산 흐름\n",
    "a $\\rightarrow$ b n$\\rightarrow$ $\\rightarrow$ c $\\rightarrow$ out\n",
    "\n",
    "$$\\frac{\\sigma out}{\\sigma a} = ?$$\n",
    "\n",
    "- backward()를 통해\n",
    "a $\\leftarrow$ b n$\\leftarrow$ $\\leftarrow$ c $\\leftarrow$ out 을 계산하면\n",
    "\n",
    "$\\frac{\\sigma out}{\\sigma a} = ?$ 값이 a.grad에 채워짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2,2,)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2,2,requires_grad=True)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(a.data)\n",
    "print(a.grad)\n",
    "print(a.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "b = a+2\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9.],\n",
      "        [9., 9.]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "c = b**2\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = c.sum()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a의 grad_fn이 None인 이유는 직접적으로 계산한 부분이 없었기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[6., 6.],\n",
      "        [6., 6.]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(a.data)\n",
    "print(a.grad)\n",
    "print(a.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "None\n",
      "<AddBackward0 object at 0x7fc26021d790>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/psh/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(b.data)\n",
    "print(b.grad)\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9.],\n",
      "        [9., 9.]])\n",
      "None\n",
      "<PowBackward0 object at 0x7fc260220d10>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/psh/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(c.data)\n",
    "print(c.grad)\n",
    "print(c.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36.)\n",
      "None\n",
      "<SumBackward0 object at 0x7fc26010f750>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/psh/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(out.data)\n",
    "print(out.grad)\n",
    "print(out.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자동 미분 흐름 다시 보기(2)\n",
    "- grad값을 넣어서 backward\n",
    "- 아래의 코드에서 .grad값이 None은 gradient값이 필요하지 않기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3,requires_grad=True)\n",
    "y = (x**2)\n",
    "z = y**2+x\n",
    "out = z.sum()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = torch.Tensor([0.1,1,100])\n",
    "z.backward(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "tensor([  0.5000,   5.0000, 500.0000])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.data)\n",
    "print(x.grad)\n",
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "None\n",
      "<PowBackward0 object at 0x7fc2601199d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/psh/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(y.data)\n",
    "print(y.grad)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2.])\n",
      "None\n",
      "<AddBackward0 object at 0x7fc260127b50>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/psh/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(z.data)\n",
    "print(z.grad)\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn & nn.functional\n",
    "- 두 패키지가 같은 기능이지만 방식이 조금 다름\n",
    "- 위의 autograd 관련 작업들을 두 패키지를 통해 진행할 수 있음\n",
    "- 텐서를 직접 다룰 때 requires_grad와 같은 방식으로 진행할 수 있음\n",
    "- 결론적으로, torch.nn은 attribute를 활용해 state를 저장하고 활용하고, torch.nn.functional로 구현한 함수의 경우에는 인스턴트화 시킬 필요 없이 사용이 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn 패키지\n",
    "- 주로 가중치(weights), 편향(bias)값들이 내부에서 자동으로 생성되는 레이어들을 사용할 때\n",
    "    - 따라서, weight 값들을 직접 선언 안함\n",
    "- 예시\n",
    "    - Containers\n",
    "    - Convolution Layers\n",
    "    - Pooling Layers\n",
    "    - Padding Layers\n",
    "    - Non-linear Activation(weigth sum, nonlinearity)\n",
    "    - Non-linear Activation(other)\n",
    "    - Normalization Layers\n",
    "    - Recurrent Layers\n",
    "    - Transformer Layers\n",
    "    - Linear Layers\n",
    "    - Dropout Layers\n",
    "    - Sparse Layers\n",
    "    - Distance Function\n",
    "    - Loss Function\n",
    "    - ..\n",
    "- https://pytorch.org/docs/stable/nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convolution Layer 예시(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[3.7906e-01, 9.9525e-01, 1.9568e-01,  ..., 3.9829e-01,\n",
      "           2.4994e-01, 1.4174e-02],\n",
      "          [6.5143e-01, 9.4347e-01, 6.2784e-01,  ..., 2.3321e-01,\n",
      "           7.2423e-01, 8.0199e-01],\n",
      "          [7.1425e-01, 8.3368e-01, 2.9249e-01,  ..., 5.3348e-01,\n",
      "           8.2284e-01, 3.7016e-01],\n",
      "          ...,\n",
      "          [5.6017e-02, 1.6813e-01, 9.7666e-03,  ..., 7.3853e-02,\n",
      "           2.2486e-01, 1.3238e-01],\n",
      "          [5.6317e-01, 5.6670e-01, 5.0312e-01,  ..., 2.7604e-01,\n",
      "           7.9872e-01, 6.4918e-01],\n",
      "          [2.8630e-01, 2.0067e-01, 1.4384e-01,  ..., 7.6706e-01,\n",
      "           9.9230e-01, 9.0663e-03]],\n",
      "\n",
      "         [[3.7502e-01, 6.5827e-01, 3.3712e-01,  ..., 3.1638e-01,\n",
      "           2.8253e-01, 7.0979e-01],\n",
      "          [4.2055e-01, 7.7894e-02, 2.6139e-01,  ..., 3.1720e-01,\n",
      "           7.2675e-01, 8.0966e-02],\n",
      "          [6.7552e-02, 3.5239e-01, 7.8460e-01,  ..., 1.2997e-01,\n",
      "           9.0277e-02, 9.5489e-03],\n",
      "          ...,\n",
      "          [9.4889e-01, 6.3711e-01, 5.6792e-01,  ..., 1.7748e-02,\n",
      "           4.4598e-01, 4.6910e-01],\n",
      "          [3.5239e-01, 7.4495e-01, 5.7903e-02,  ..., 6.0782e-01,\n",
      "           1.3829e-01, 1.5511e-02],\n",
      "          [9.7046e-01, 3.5406e-01, 6.4885e-01,  ..., 8.4823e-01,\n",
      "           1.1743e-01, 5.6278e-02]],\n",
      "\n",
      "         [[7.4113e-01, 6.2210e-01, 3.3659e-01,  ..., 6.5807e-02,\n",
      "           4.6567e-01, 2.7450e-01],\n",
      "          [8.9056e-01, 4.5795e-01, 3.3667e-02,  ..., 7.0279e-01,\n",
      "           9.3137e-01, 7.0280e-01],\n",
      "          [2.2937e-01, 8.5700e-01, 3.6063e-01,  ..., 7.0620e-01,\n",
      "           6.8419e-01, 7.3110e-01],\n",
      "          ...,\n",
      "          [7.3855e-01, 2.1084e-01, 6.1930e-01,  ..., 9.2597e-01,\n",
      "           3.2701e-01, 2.1902e-01],\n",
      "          [9.4496e-01, 2.6987e-01, 7.1423e-01,  ..., 2.4086e-01,\n",
      "           5.9543e-01, 5.4416e-01],\n",
      "          [2.9411e-01, 6.1425e-01, 7.3967e-02,  ..., 9.7522e-01,\n",
      "           2.0059e-02, 3.3128e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[8.5064e-01, 5.2295e-01, 1.9179e-01,  ..., 5.8177e-01,\n",
      "           5.1352e-01, 7.7400e-01],\n",
      "          [2.2582e-01, 6.7532e-01, 7.5020e-01,  ..., 5.5233e-01,\n",
      "           5.7008e-01, 2.8156e-01],\n",
      "          [8.8308e-01, 4.3572e-01, 8.9407e-01,  ..., 8.0484e-01,\n",
      "           7.5074e-01, 4.3819e-01],\n",
      "          ...,\n",
      "          [8.6965e-01, 7.9530e-01, 1.1558e-01,  ..., 1.8622e-01,\n",
      "           6.2515e-01, 1.0993e-01],\n",
      "          [7.6008e-01, 1.9834e-01, 4.9290e-01,  ..., 1.7380e-02,\n",
      "           7.1967e-01, 2.5175e-01],\n",
      "          [6.8410e-01, 3.4813e-01, 1.0816e-01,  ..., 2.8069e-01,\n",
      "           6.9377e-01, 6.4203e-01]],\n",
      "\n",
      "         [[5.4365e-01, 8.2918e-01, 2.2170e-01,  ..., 6.5156e-01,\n",
      "           8.0356e-01, 8.8085e-01],\n",
      "          [4.5768e-01, 3.0220e-01, 4.4031e-01,  ..., 1.4585e-01,\n",
      "           1.5020e-01, 9.0569e-01],\n",
      "          [4.4549e-01, 3.6601e-01, 6.7962e-01,  ..., 9.0697e-01,\n",
      "           9.8921e-01, 7.8089e-01],\n",
      "          ...,\n",
      "          [8.1500e-01, 1.6230e-01, 3.7086e-02,  ..., 8.1011e-01,\n",
      "           5.9882e-01, 1.8160e-01],\n",
      "          [2.5389e-01, 7.7883e-01, 8.6761e-01,  ..., 6.2657e-01,\n",
      "           7.6372e-01, 6.5302e-01],\n",
      "          [7.1869e-01, 8.1533e-01, 1.3694e-02,  ..., 4.9848e-01,\n",
      "           8.5969e-01, 7.8305e-01]],\n",
      "\n",
      "         [[2.2730e-02, 6.7574e-01, 2.9462e-01,  ..., 6.5630e-01,\n",
      "           9.0206e-01, 3.8304e-01],\n",
      "          [6.3342e-01, 2.8948e-02, 3.7856e-01,  ..., 1.7380e-01,\n",
      "           9.6966e-01, 2.7051e-01],\n",
      "          [3.5864e-01, 9.5935e-01, 9.5723e-01,  ..., 5.4608e-01,\n",
      "           1.3018e-01, 2.1315e-01],\n",
      "          ...,\n",
      "          [5.0698e-01, 8.7390e-01, 7.2822e-01,  ..., 4.4042e-01,\n",
      "           1.7562e-01, 8.3503e-02],\n",
      "          [4.4121e-01, 3.4583e-01, 8.9470e-01,  ..., 5.3596e-02,\n",
      "           1.0868e-01, 9.3972e-01],\n",
      "          [4.2098e-01, 1.8141e-01, 3.6200e-01,  ..., 4.0454e-01,\n",
      "           3.0027e-01, 8.5940e-01]]],\n",
      "\n",
      "\n",
      "        [[[3.0587e-01, 4.7269e-01, 1.1434e-01,  ..., 8.3659e-01,\n",
      "           8.0162e-01, 5.4716e-01],\n",
      "          [7.8618e-01, 4.8945e-01, 4.2624e-01,  ..., 7.3955e-01,\n",
      "           9.2470e-01, 8.6446e-01],\n",
      "          [7.1638e-01, 1.0729e-01, 5.2534e-01,  ..., 8.9281e-01,\n",
      "           6.9772e-01, 5.9629e-02],\n",
      "          ...,\n",
      "          [6.6151e-01, 5.0544e-02, 8.4658e-01,  ..., 6.4735e-01,\n",
      "           3.0709e-01, 2.9843e-01],\n",
      "          [5.7160e-01, 5.7367e-01, 6.9993e-01,  ..., 3.9244e-02,\n",
      "           6.6550e-01, 5.5161e-01],\n",
      "          [8.8368e-01, 1.0689e-01, 3.4086e-01,  ..., 4.5874e-01,\n",
      "           7.1026e-01, 8.4209e-01]],\n",
      "\n",
      "         [[9.6178e-01, 3.9109e-01, 3.0556e-01,  ..., 5.1420e-01,\n",
      "           2.6535e-01, 6.1986e-01],\n",
      "          [1.7950e-01, 6.7241e-02, 6.7245e-01,  ..., 9.4678e-01,\n",
      "           3.7982e-01, 3.5125e-01],\n",
      "          [2.6416e-01, 6.7962e-02, 1.0492e-01,  ..., 7.2954e-01,\n",
      "           8.3628e-01, 2.3583e-01],\n",
      "          ...,\n",
      "          [5.5934e-01, 2.5128e-02, 1.5459e-01,  ..., 5.9626e-01,\n",
      "           6.4395e-01, 9.2574e-01],\n",
      "          [5.8761e-01, 8.6047e-01, 1.5888e-01,  ..., 4.0493e-01,\n",
      "           8.5266e-01, 4.8744e-02],\n",
      "          [4.9872e-01, 4.9821e-01, 5.3626e-01,  ..., 1.6564e-01,\n",
      "           5.2876e-01, 7.7940e-01]],\n",
      "\n",
      "         [[5.5529e-02, 9.8293e-01, 5.7983e-01,  ..., 2.0002e-01,\n",
      "           9.0175e-02, 9.3771e-01],\n",
      "          [1.2215e-01, 7.8069e-01, 3.2450e-01,  ..., 4.1078e-01,\n",
      "           1.1027e-01, 4.0353e-01],\n",
      "          [4.9969e-01, 4.6399e-01, 9.0779e-01,  ..., 8.3950e-01,\n",
      "           4.3711e-02, 2.3005e-01],\n",
      "          ...,\n",
      "          [3.7432e-01, 6.0835e-01, 1.6109e-02,  ..., 4.8192e-01,\n",
      "           7.2105e-01, 7.4652e-01],\n",
      "          [7.1881e-01, 3.5192e-01, 3.3028e-01,  ..., 9.6629e-01,\n",
      "           3.2817e-01, 5.9785e-01],\n",
      "          [9.9135e-01, 3.3780e-01, 8.7139e-01,  ..., 8.6941e-01,\n",
      "           9.8366e-01, 2.8285e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[5.5661e-01, 8.9677e-01, 7.2660e-01,  ..., 5.8124e-01,\n",
      "           9.3990e-01, 3.9351e-01],\n",
      "          [8.0209e-01, 4.4548e-02, 3.2281e-01,  ..., 8.6313e-01,\n",
      "           1.1238e-01, 9.9086e-01],\n",
      "          [1.7972e-01, 4.5636e-01, 3.4366e-01,  ..., 5.4053e-01,\n",
      "           7.0463e-02, 6.8893e-01],\n",
      "          ...,\n",
      "          [2.0086e-01, 1.3018e-01, 3.2763e-01,  ..., 5.7296e-01,\n",
      "           1.2337e-01, 1.3674e-02],\n",
      "          [9.9455e-01, 3.6453e-01, 8.7285e-02,  ..., 8.3798e-01,\n",
      "           6.0681e-01, 3.7160e-01],\n",
      "          [2.3564e-01, 6.7427e-02, 5.7603e-01,  ..., 9.3480e-01,\n",
      "           9.9262e-01, 5.5679e-01]],\n",
      "\n",
      "         [[1.8898e-01, 6.1509e-02, 7.3056e-01,  ..., 9.1531e-01,\n",
      "           5.4153e-01, 4.3676e-01],\n",
      "          [1.1277e-01, 5.6778e-01, 5.8406e-01,  ..., 6.3755e-01,\n",
      "           5.9426e-01, 9.7341e-01],\n",
      "          [1.6137e-01, 8.1575e-01, 9.8167e-01,  ..., 7.1722e-01,\n",
      "           3.3276e-01, 3.2903e-01],\n",
      "          ...,\n",
      "          [6.7460e-01, 4.3226e-01, 1.2616e-02,  ..., 3.4860e-03,\n",
      "           9.9650e-01, 2.5242e-01],\n",
      "          [9.3032e-01, 5.3106e-01, 4.2536e-02,  ..., 6.5409e-01,\n",
      "           9.5565e-01, 5.2518e-01],\n",
      "          [4.4119e-01, 6.2536e-01, 3.0415e-01,  ..., 6.6790e-01,\n",
      "           3.5364e-01, 4.4842e-01]],\n",
      "\n",
      "         [[3.9310e-01, 1.6063e-01, 1.6903e-01,  ..., 1.7204e-01,\n",
      "           1.9736e-01, 2.3580e-01],\n",
      "          [8.5380e-01, 3.1746e-01, 6.1801e-01,  ..., 7.8311e-01,\n",
      "           2.5739e-01, 8.9931e-01],\n",
      "          [7.3418e-01, 3.4901e-01, 2.7331e-01,  ..., 2.7951e-01,\n",
      "           4.9562e-01, 1.6633e-01],\n",
      "          ...,\n",
      "          [4.0525e-01, 3.4709e-01, 5.5185e-01,  ..., 8.4595e-01,\n",
      "           5.6098e-01, 4.3410e-01],\n",
      "          [3.4980e-01, 8.4026e-01, 3.5281e-01,  ..., 4.1314e-02,\n",
      "           9.9421e-01, 5.4094e-02],\n",
      "          [3.1555e-01, 8.4327e-01, 2.9203e-01,  ..., 7.0615e-01,\n",
      "           3.1043e-01, 4.5633e-01]]],\n",
      "\n",
      "\n",
      "        [[[2.5797e-01, 1.4783e-01, 5.7247e-01,  ..., 7.6599e-01,\n",
      "           7.2211e-01, 7.9383e-02],\n",
      "          [1.5384e-01, 2.0331e-02, 2.3789e-01,  ..., 4.0292e-01,\n",
      "           1.9778e-01, 8.3708e-01],\n",
      "          [2.9223e-01, 4.0468e-01, 3.2043e-01,  ..., 2.7651e-01,\n",
      "           1.1961e-01, 8.4300e-01],\n",
      "          ...,\n",
      "          [6.7238e-02, 6.7904e-01, 7.1224e-01,  ..., 7.6696e-02,\n",
      "           5.0916e-01, 2.9687e-02],\n",
      "          [1.1862e-01, 9.8455e-03, 9.0334e-01,  ..., 9.8392e-01,\n",
      "           8.5381e-01, 1.2881e-02],\n",
      "          [6.0491e-01, 4.2126e-01, 3.6902e-01,  ..., 3.4112e-01,\n",
      "           4.0866e-01, 6.0970e-01]],\n",
      "\n",
      "         [[5.3756e-01, 4.8779e-01, 8.4021e-01,  ..., 2.6220e-01,\n",
      "           2.1672e-03, 8.4056e-01],\n",
      "          [7.8198e-01, 7.8566e-01, 2.8706e-01,  ..., 1.8919e-01,\n",
      "           7.4769e-01, 5.4696e-01],\n",
      "          [8.5197e-01, 5.7630e-02, 6.3324e-01,  ..., 8.0841e-01,\n",
      "           6.2545e-01, 2.4667e-01],\n",
      "          ...,\n",
      "          [6.0405e-01, 9.5338e-01, 4.1493e-02,  ..., 3.2996e-01,\n",
      "           4.0040e-01, 8.6704e-01],\n",
      "          [8.8719e-01, 5.0052e-01, 8.1977e-01,  ..., 8.2431e-02,\n",
      "           7.6245e-01, 1.9079e-01],\n",
      "          [2.5471e-01, 5.4733e-01, 2.1321e-02,  ..., 6.1794e-01,\n",
      "           2.9273e-01, 9.3574e-01]],\n",
      "\n",
      "         [[7.3362e-01, 3.0589e-02, 6.2246e-01,  ..., 2.9938e-01,\n",
      "           6.4028e-02, 7.1771e-01],\n",
      "          [5.0935e-01, 7.3417e-01, 2.8151e-01,  ..., 3.3341e-01,\n",
      "           4.3738e-01, 4.4684e-01],\n",
      "          [7.0371e-02, 9.3040e-02, 9.8179e-01,  ..., 3.9898e-01,\n",
      "           9.6356e-01, 2.8680e-03],\n",
      "          ...,\n",
      "          [8.9735e-01, 7.7023e-01, 8.6660e-01,  ..., 9.2738e-01,\n",
      "           3.2634e-02, 5.4406e-01],\n",
      "          [9.2263e-01, 7.3459e-01, 3.0161e-01,  ..., 2.4685e-01,\n",
      "           6.1751e-01, 2.5307e-01],\n",
      "          [9.7285e-01, 9.3582e-01, 4.6109e-02,  ..., 3.3506e-01,\n",
      "           1.4115e-01, 4.4443e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.6641e-01, 7.4154e-01, 9.9945e-01,  ..., 7.5254e-01,\n",
      "           4.7610e-01, 4.1117e-01],\n",
      "          [7.8347e-01, 7.0381e-02, 5.4384e-01,  ..., 5.0093e-01,\n",
      "           1.4398e-01, 3.6277e-01],\n",
      "          [8.0347e-01, 2.3609e-02, 8.2028e-01,  ..., 2.8146e-01,\n",
      "           5.3560e-02, 3.6810e-01],\n",
      "          ...,\n",
      "          [1.3214e-01, 5.4062e-01, 5.4636e-02,  ..., 8.1694e-01,\n",
      "           7.6018e-01, 6.5036e-01],\n",
      "          [3.2409e-01, 1.8395e-01, 1.8639e-01,  ..., 6.3142e-01,\n",
      "           2.6604e-01, 9.4369e-01],\n",
      "          [2.4703e-01, 8.1269e-01, 9.8986e-02,  ..., 7.5864e-01,\n",
      "           1.1377e-01, 8.1541e-01]],\n",
      "\n",
      "         [[9.5135e-01, 8.2994e-01, 9.5718e-01,  ..., 8.5151e-01,\n",
      "           4.8940e-02, 8.4372e-01],\n",
      "          [1.9248e-01, 3.8358e-01, 3.8612e-01,  ..., 3.5389e-01,\n",
      "           1.3847e-01, 5.7355e-01],\n",
      "          [4.0174e-01, 6.8788e-01, 8.5130e-01,  ..., 1.8916e-01,\n",
      "           5.7988e-01, 5.8180e-01],\n",
      "          ...,\n",
      "          [3.0455e-01, 1.0695e-01, 8.8490e-01,  ..., 3.5872e-01,\n",
      "           9.4537e-01, 8.2933e-01],\n",
      "          [5.2051e-01, 5.2234e-01, 3.5931e-01,  ..., 3.1715e-03,\n",
      "           3.9528e-01, 6.3945e-01],\n",
      "          [2.6280e-01, 9.8145e-01, 4.8899e-01,  ..., 7.6048e-01,\n",
      "           5.1914e-01, 2.2684e-01]],\n",
      "\n",
      "         [[3.0830e-01, 4.7627e-01, 4.3941e-01,  ..., 4.1605e-01,\n",
      "           4.0863e-02, 8.8120e-01],\n",
      "          [6.3727e-01, 7.2707e-01, 6.1964e-03,  ..., 8.5601e-01,\n",
      "           9.1553e-01, 7.4912e-01],\n",
      "          [5.4935e-01, 9.3456e-01, 4.8152e-01,  ..., 4.2950e-01,\n",
      "           4.0658e-01, 3.8763e-01],\n",
      "          ...,\n",
      "          [3.2867e-01, 1.1960e-01, 8.5668e-01,  ..., 3.5421e-01,\n",
      "           9.0611e-01, 5.3599e-01],\n",
      "          [9.7399e-01, 6.3166e-01, 4.9444e-01,  ..., 7.4340e-01,\n",
      "           6.3146e-01, 8.0481e-01],\n",
      "          [5.9015e-01, 6.9250e-02, 5.6632e-01,  ..., 7.5747e-01,\n",
      "           2.2462e-01, 4.5704e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[4.9243e-01, 3.2962e-01, 1.7163e-01,  ..., 9.8049e-01,\n",
      "           4.0262e-01, 6.1383e-01],\n",
      "          [3.0186e-01, 4.2844e-01, 3.6446e-01,  ..., 5.3625e-01,\n",
      "           3.6512e-01, 4.3942e-01],\n",
      "          [3.1563e-01, 2.0175e-01, 3.5531e-01,  ..., 3.5675e-01,\n",
      "           9.3033e-01, 6.9906e-01],\n",
      "          ...,\n",
      "          [9.2416e-01, 2.8329e-01, 9.3200e-01,  ..., 8.4328e-01,\n",
      "           8.3777e-01, 5.5306e-01],\n",
      "          [7.0890e-01, 2.8948e-01, 4.9278e-01,  ..., 6.8985e-01,\n",
      "           9.0699e-01, 3.5428e-01],\n",
      "          [2.2848e-01, 8.6543e-01, 2.6199e-01,  ..., 8.5364e-01,\n",
      "           3.4985e-01, 4.9151e-02]],\n",
      "\n",
      "         [[2.6047e-01, 8.9104e-01, 9.3982e-01,  ..., 1.7677e-01,\n",
      "           7.7344e-01, 6.2419e-01],\n",
      "          [1.7340e-01, 7.6178e-01, 1.4906e-01,  ..., 3.9504e-01,\n",
      "           4.5739e-01, 3.2224e-01],\n",
      "          [1.0319e-02, 5.2014e-01, 8.3884e-01,  ..., 3.4276e-01,\n",
      "           9.3879e-01, 1.7122e-01],\n",
      "          ...,\n",
      "          [2.4626e-01, 8.8740e-01, 4.8201e-01,  ..., 3.0730e-01,\n",
      "           9.8924e-01, 7.6889e-01],\n",
      "          [3.1975e-01, 4.9785e-02, 4.0575e-01,  ..., 8.5729e-01,\n",
      "           6.0595e-01, 2.4429e-01],\n",
      "          [7.3538e-01, 4.7230e-01, 2.0369e-01,  ..., 9.2104e-02,\n",
      "           7.7881e-01, 7.7681e-01]],\n",
      "\n",
      "         [[2.8275e-01, 7.0109e-01, 5.6530e-01,  ..., 3.0838e-01,\n",
      "           4.7722e-01, 3.4425e-01],\n",
      "          [7.5825e-01, 5.2457e-01, 9.4893e-01,  ..., 7.3660e-01,\n",
      "           1.4966e-01, 1.5599e-01],\n",
      "          [7.8006e-01, 5.0099e-02, 2.9769e-01,  ..., 3.3695e-01,\n",
      "           5.1601e-01, 3.2730e-01],\n",
      "          ...,\n",
      "          [4.5038e-01, 4.7925e-01, 6.0995e-01,  ..., 8.3295e-01,\n",
      "           2.5987e-01, 2.5100e-04],\n",
      "          [6.3935e-01, 5.8968e-01, 3.3912e-01,  ..., 7.7628e-01,\n",
      "           9.9479e-01, 7.4214e-01],\n",
      "          [1.3452e-01, 5.0556e-01, 4.9711e-01,  ..., 6.5986e-01,\n",
      "           4.0874e-01, 2.0730e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.0472e-01, 8.3210e-01, 1.3242e-01,  ..., 8.5307e-02,\n",
      "           5.7227e-02, 9.4526e-01],\n",
      "          [4.4423e-01, 7.5003e-01, 2.3696e-01,  ..., 1.4406e-03,\n",
      "           5.2339e-01, 3.4184e-01],\n",
      "          [9.8503e-01, 6.5936e-01, 6.0924e-02,  ..., 3.5117e-01,\n",
      "           2.9690e-01, 5.3315e-01],\n",
      "          ...,\n",
      "          [7.3032e-01, 4.5574e-01, 9.6598e-01,  ..., 6.9983e-01,\n",
      "           6.3127e-01, 7.6278e-01],\n",
      "          [1.0787e-01, 7.3766e-01, 5.4495e-01,  ..., 7.3529e-01,\n",
      "           1.7615e-02, 1.6388e-01],\n",
      "          [8.3789e-02, 1.1756e-01, 8.1200e-01,  ..., 5.3098e-01,\n",
      "           5.4528e-01, 7.3535e-01]],\n",
      "\n",
      "         [[8.3939e-01, 8.0589e-01, 5.2397e-01,  ..., 2.6164e-01,\n",
      "           1.4852e-01, 7.0350e-02],\n",
      "          [9.0587e-01, 6.0262e-01, 7.6373e-01,  ..., 8.9807e-01,\n",
      "           9.0953e-01, 6.2765e-01],\n",
      "          [3.7655e-01, 4.2205e-01, 2.5834e-01,  ..., 3.6044e-02,\n",
      "           1.2055e-02, 6.0860e-01],\n",
      "          ...,\n",
      "          [7.2589e-01, 7.6346e-01, 3.8744e-01,  ..., 4.6041e-01,\n",
      "           6.2266e-01, 8.7666e-01],\n",
      "          [5.0685e-01, 4.0481e-01, 4.8149e-02,  ..., 6.1017e-01,\n",
      "           2.0109e-03, 3.8487e-01],\n",
      "          [4.6019e-01, 9.7417e-01, 2.8234e-01,  ..., 6.0376e-01,\n",
      "           8.8934e-01, 7.3327e-01]],\n",
      "\n",
      "         [[6.8494e-01, 5.5952e-01, 3.0227e-01,  ..., 6.8555e-01,\n",
      "           6.7341e-01, 5.1227e-01],\n",
      "          [2.4485e-01, 5.8758e-01, 7.1043e-01,  ..., 2.8488e-01,\n",
      "           5.8396e-01, 6.7247e-01],\n",
      "          [2.1410e-01, 4.9076e-01, 8.2911e-01,  ..., 2.2717e-01,\n",
      "           2.0027e-01, 4.0816e-01],\n",
      "          ...,\n",
      "          [5.1080e-01, 8.6468e-01, 9.9826e-01,  ..., 3.8045e-01,\n",
      "           4.3770e-02, 7.1039e-01],\n",
      "          [8.8311e-01, 2.7804e-01, 3.1971e-02,  ..., 2.0123e-01,\n",
      "           3.9376e-01, 3.9144e-01],\n",
      "          [4.9595e-01, 3.6356e-01, 3.4725e-01,  ..., 5.7275e-01,\n",
      "           5.9335e-01, 9.7459e-01]]],\n",
      "\n",
      "\n",
      "        [[[6.1723e-01, 1.6362e-01, 6.6192e-01,  ..., 6.0068e-01,\n",
      "           6.9135e-01, 5.4775e-02],\n",
      "          [5.6707e-02, 3.3354e-01, 7.1954e-01,  ..., 4.5131e-01,\n",
      "           6.8246e-01, 2.7983e-01],\n",
      "          [7.5913e-01, 2.4338e-02, 4.9570e-01,  ..., 9.1145e-01,\n",
      "           1.9022e-01, 2.6583e-01],\n",
      "          ...,\n",
      "          [7.6957e-01, 4.8724e-02, 9.8681e-04,  ..., 2.7423e-01,\n",
      "           7.2124e-03, 4.8347e-01],\n",
      "          [3.5307e-01, 8.1524e-01, 2.5162e-01,  ..., 1.8900e-01,\n",
      "           4.1927e-01, 4.0398e-01],\n",
      "          [9.3046e-01, 2.2416e-01, 9.1831e-02,  ..., 3.4283e-01,\n",
      "           8.6457e-01, 4.8025e-01]],\n",
      "\n",
      "         [[6.5608e-01, 9.2225e-01, 7.2191e-01,  ..., 4.3594e-01,\n",
      "           5.3798e-01, 3.0950e-02],\n",
      "          [1.0571e-01, 4.2205e-01, 6.4205e-02,  ..., 9.3463e-01,\n",
      "           2.7318e-01, 4.2468e-01],\n",
      "          [3.5167e-01, 2.5199e-01, 9.4681e-01,  ..., 6.3906e-01,\n",
      "           1.8383e-01, 3.8003e-01],\n",
      "          ...,\n",
      "          [4.7872e-01, 3.2164e-01, 2.8554e-01,  ..., 6.6824e-01,\n",
      "           5.6686e-01, 9.5443e-01],\n",
      "          [9.3857e-01, 8.5296e-01, 4.4042e-01,  ..., 9.6246e-01,\n",
      "           9.0349e-01, 3.0588e-01],\n",
      "          [7.8999e-01, 1.0738e-01, 4.8021e-01,  ..., 2.3312e-01,\n",
      "           4.1635e-01, 4.4871e-01]],\n",
      "\n",
      "         [[9.4584e-01, 1.4952e-01, 3.9545e-01,  ..., 3.9353e-01,\n",
      "           6.2207e-02, 6.6224e-01],\n",
      "          [4.8799e-01, 6.6592e-01, 6.3268e-01,  ..., 8.5505e-01,\n",
      "           3.0650e-01, 2.6312e-01],\n",
      "          [3.8143e-01, 6.0019e-02, 8.0264e-01,  ..., 3.0078e-01,\n",
      "           2.0090e-01, 1.5606e-01],\n",
      "          ...,\n",
      "          [1.3040e-01, 6.8713e-01, 1.2779e-01,  ..., 3.2835e-01,\n",
      "           7.0274e-01, 7.7418e-01],\n",
      "          [1.3473e-01, 2.0590e-01, 8.5834e-01,  ..., 6.5882e-01,\n",
      "           8.5752e-01, 2.0287e-01],\n",
      "          [9.1485e-01, 8.4752e-01, 4.4371e-01,  ..., 9.3574e-01,\n",
      "           2.0708e-01, 3.6459e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.0926e-01, 9.7480e-01, 8.9004e-01,  ..., 7.4734e-02,\n",
      "           5.0810e-02, 4.2975e-01],\n",
      "          [5.8378e-01, 8.2475e-02, 9.2676e-01,  ..., 1.1950e-01,\n",
      "           9.1250e-01, 9.3858e-01],\n",
      "          [7.0322e-01, 8.3214e-01, 2.1589e-01,  ..., 6.7060e-01,\n",
      "           5.6951e-01, 8.1905e-01],\n",
      "          ...,\n",
      "          [6.9364e-02, 1.4940e-02, 1.8852e-01,  ..., 1.9967e-01,\n",
      "           4.3689e-01, 2.8506e-01],\n",
      "          [9.7553e-01, 9.3946e-01, 3.2799e-01,  ..., 1.4850e-01,\n",
      "           6.6496e-01, 5.8475e-01],\n",
      "          [3.5741e-01, 5.8288e-01, 3.1864e-01,  ..., 5.6296e-01,\n",
      "           4.1937e-01, 7.6789e-01]],\n",
      "\n",
      "         [[7.3498e-01, 4.0772e-02, 6.4431e-01,  ..., 8.6512e-02,\n",
      "           1.5264e-02, 2.2728e-01],\n",
      "          [5.0898e-01, 8.1034e-01, 5.8949e-01,  ..., 4.0103e-01,\n",
      "           4.6281e-01, 9.2850e-01],\n",
      "          [6.1541e-01, 8.0756e-01, 9.3568e-01,  ..., 3.7765e-01,\n",
      "           1.3651e-01, 4.0415e-01],\n",
      "          ...,\n",
      "          [6.6876e-01, 4.8424e-02, 1.7829e-01,  ..., 5.0662e-01,\n",
      "           6.5266e-01, 1.7193e-01],\n",
      "          [1.8544e-02, 4.6838e-01, 1.5655e-01,  ..., 3.8608e-01,\n",
      "           4.4558e-01, 3.6029e-02],\n",
      "          [7.1945e-02, 5.7192e-01, 6.4481e-01,  ..., 6.9025e-02,\n",
      "           4.4095e-01, 4.9344e-03]],\n",
      "\n",
      "         [[3.1947e-01, 3.5143e-02, 5.8736e-01,  ..., 6.9684e-01,\n",
      "           1.3199e-01, 3.9511e-01],\n",
      "          [4.8807e-01, 7.3124e-01, 6.5895e-01,  ..., 8.0390e-01,\n",
      "           9.5323e-01, 3.1674e-01],\n",
      "          [7.9182e-01, 6.7631e-01, 3.0399e-02,  ..., 5.0568e-01,\n",
      "           2.8122e-01, 5.7941e-01],\n",
      "          ...,\n",
      "          [1.3546e-01, 2.3903e-01, 6.7766e-01,  ..., 5.9104e-01,\n",
      "           8.0754e-01, 1.7228e-01],\n",
      "          [4.3297e-01, 2.1061e-01, 4.6266e-01,  ..., 1.2091e-01,\n",
      "           3.1481e-01, 5.2441e-01],\n",
      "          [9.3029e-01, 8.2424e-01, 2.6965e-01,  ..., 5.5989e-01,\n",
      "           2.6433e-01, 7.2937e-01]]],\n",
      "\n",
      "\n",
      "        [[[3.8623e-02, 6.8722e-01, 8.9058e-01,  ..., 9.9170e-01,\n",
      "           7.1983e-01, 9.6183e-01],\n",
      "          [4.5557e-01, 8.5793e-01, 2.2285e-01,  ..., 2.0711e-01,\n",
      "           9.2317e-01, 7.6915e-01],\n",
      "          [4.6121e-01, 1.7820e-02, 6.4147e-01,  ..., 3.2521e-01,\n",
      "           7.8457e-01, 1.8009e-01],\n",
      "          ...,\n",
      "          [6.0049e-01, 3.9087e-01, 2.2699e-01,  ..., 8.7840e-01,\n",
      "           8.4480e-01, 2.1650e-01],\n",
      "          [9.4722e-01, 3.9072e-01, 2.8940e-01,  ..., 1.5270e-01,\n",
      "           8.9193e-01, 9.7832e-01],\n",
      "          [4.3056e-01, 3.9603e-01, 2.6176e-01,  ..., 2.0506e-01,\n",
      "           1.1615e-01, 7.6600e-01]],\n",
      "\n",
      "         [[2.5251e-01, 7.3664e-01, 3.6228e-01,  ..., 7.9251e-01,\n",
      "           1.4442e-01, 8.5461e-01],\n",
      "          [1.0942e-01, 7.3779e-01, 7.5373e-01,  ..., 9.0356e-01,\n",
      "           3.9993e-01, 7.8314e-01],\n",
      "          [1.9655e-01, 9.8883e-01, 9.3815e-01,  ..., 3.3154e-01,\n",
      "           1.8057e-01, 9.4599e-01],\n",
      "          ...,\n",
      "          [8.4771e-01, 9.2542e-01, 9.7675e-01,  ..., 3.7244e-01,\n",
      "           8.3559e-01, 2.5929e-01],\n",
      "          [6.4768e-02, 4.6546e-01, 3.9393e-01,  ..., 8.6980e-03,\n",
      "           9.3154e-01, 8.9579e-02],\n",
      "          [5.7262e-01, 3.1729e-01, 8.0947e-01,  ..., 8.9947e-01,\n",
      "           7.3247e-01, 5.8649e-01]],\n",
      "\n",
      "         [[7.4756e-01, 8.2278e-01, 6.7395e-01,  ..., 6.0583e-01,\n",
      "           1.1930e-01, 7.6589e-01],\n",
      "          [6.2886e-01, 5.9320e-01, 8.9355e-01,  ..., 6.6291e-01,\n",
      "           8.5752e-01, 3.4690e-01],\n",
      "          [6.8621e-01, 7.3468e-01, 7.7553e-01,  ..., 4.8009e-01,\n",
      "           3.2093e-01, 3.7223e-01],\n",
      "          ...,\n",
      "          [5.4859e-01, 4.1126e-01, 1.6042e-01,  ..., 7.5253e-01,\n",
      "           1.4821e-01, 5.0387e-01],\n",
      "          [4.8446e-01, 3.3469e-01, 8.1241e-01,  ..., 6.3536e-01,\n",
      "           9.4538e-01, 3.2758e-01],\n",
      "          [2.6210e-01, 2.0219e-01, 5.6552e-01,  ..., 8.6229e-01,\n",
      "           9.8114e-01, 6.8461e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.4000e-02, 6.3983e-01, 1.7455e-01,  ..., 8.0022e-01,\n",
      "           3.7859e-01, 3.5368e-02],\n",
      "          [4.9549e-01, 4.6458e-01, 1.2593e-01,  ..., 2.1019e-01,\n",
      "           3.3643e-01, 9.5794e-01],\n",
      "          [1.8125e-01, 9.0263e-01, 3.5152e-01,  ..., 1.8175e-01,\n",
      "           9.3342e-01, 3.1534e-01],\n",
      "          ...,\n",
      "          [4.8981e-01, 4.0351e-01, 6.9718e-01,  ..., 1.3465e-01,\n",
      "           9.1554e-01, 4.2517e-01],\n",
      "          [6.5606e-01, 9.1368e-02, 7.2864e-01,  ..., 9.5776e-01,\n",
      "           4.1347e-01, 8.0362e-02],\n",
      "          [6.0437e-01, 7.3337e-01, 3.6829e-01,  ..., 9.1530e-03,\n",
      "           4.2817e-01, 6.6717e-02]],\n",
      "\n",
      "         [[6.1898e-01, 9.3921e-01, 3.3990e-01,  ..., 8.2814e-01,\n",
      "           9.2946e-02, 8.9748e-01],\n",
      "          [1.1488e-01, 1.4642e-01, 9.0240e-01,  ..., 1.1378e-01,\n",
      "           7.5067e-02, 3.9107e-01],\n",
      "          [5.0580e-01, 9.9822e-01, 9.0725e-02,  ..., 4.5279e-01,\n",
      "           7.9599e-01, 5.3797e-01],\n",
      "          ...,\n",
      "          [9.2884e-02, 3.4381e-01, 6.7151e-01,  ..., 3.3248e-02,\n",
      "           7.0801e-01, 7.7587e-01],\n",
      "          [1.1422e-01, 7.4524e-01, 2.0540e-01,  ..., 2.8729e-01,\n",
      "           7.0329e-01, 4.8484e-01],\n",
      "          [6.4856e-01, 9.2182e-01, 6.2874e-01,  ..., 1.5082e-01,\n",
      "           9.8337e-01, 4.4153e-01]],\n",
      "\n",
      "         [[9.2204e-01, 3.6757e-01, 3.7723e-02,  ..., 4.1169e-01,\n",
      "           9.1852e-01, 1.6701e-01],\n",
      "          [8.7998e-01, 2.3667e-01, 3.0209e-01,  ..., 5.8283e-01,\n",
      "           6.2038e-01, 8.6103e-01],\n",
      "          [3.2250e-01, 4.3132e-01, 5.4931e-02,  ..., 4.0540e-01,\n",
      "           4.0850e-01, 1.0900e-01],\n",
      "          ...,\n",
      "          [6.3368e-01, 8.3651e-01, 1.9788e-01,  ..., 1.8437e-01,\n",
      "           8.5567e-01, 9.1670e-01],\n",
      "          [1.6128e-02, 3.2026e-01, 8.8631e-01,  ..., 2.9649e-01,\n",
      "           3.2684e-01, 3.0766e-01],\n",
      "          [4.6523e-01, 7.3306e-01, 8.0261e-01,  ..., 8.4946e-02,\n",
      "           7.7479e-01, 6.7896e-01]]]])\n",
      "tensor([[[[ 1.0152e-01,  1.1430e-01,  1.5959e-01,  ...,  3.4746e-01,\n",
      "            1.7387e-01,  1.1758e-01],\n",
      "          [-2.7131e-02, -7.2525e-02, -4.5210e-02,  ..., -4.7361e-02,\n",
      "           -1.4085e-01, -5.3002e-03],\n",
      "          [-2.9405e-02, -1.5610e-02, -2.5770e-01,  ..., -7.2770e-02,\n",
      "            2.5584e-01,  1.9532e-01],\n",
      "          ...,\n",
      "          [-2.6464e-01, -8.5860e-02, -1.6716e-02,  ..., -1.7650e-01,\n",
      "           -2.5501e-01,  1.3703e-01],\n",
      "          [-1.7004e-01, -3.7586e-01, -1.0950e-01,  ..., -2.2431e-01,\n",
      "           -1.1797e-01, -4.8985e-02],\n",
      "          [-1.2417e-01, -2.1333e-01, -2.4188e-01,  ..., -3.7579e-01,\n",
      "            4.5272e-02, -2.1571e-01]],\n",
      "\n",
      "         [[ 1.7170e-02,  3.4137e-02,  1.0071e-01,  ..., -6.1170e-02,\n",
      "           -6.1763e-02, -2.4943e-02],\n",
      "          [-4.3080e-02, -9.9233e-02, -3.4574e-01,  ..., -1.4643e-01,\n",
      "           -3.5929e-01, -8.3204e-02],\n",
      "          [-9.3189e-02, -2.7850e-02, -2.4289e-01,  ...,  6.2161e-02,\n",
      "           -9.4564e-02,  1.1017e-01],\n",
      "          ...,\n",
      "          [ 1.3233e-01, -3.0113e-02, -6.2348e-02,  ..., -6.1374e-02,\n",
      "            1.4149e-01, -2.9487e-02],\n",
      "          [-8.5328e-02, -1.7986e-01,  1.0013e-01,  ..., -4.4364e-03,\n",
      "           -9.0404e-02,  1.6887e-01],\n",
      "          [ 1.4338e-01, -1.3983e-01,  5.8746e-02,  ...,  5.5240e-02,\n",
      "           -9.1035e-02, -6.9491e-02]],\n",
      "\n",
      "         [[-1.7859e-01, -1.6566e-01,  7.0299e-02,  ..., -2.4197e-01,\n",
      "           -1.2040e-01,  5.8015e-02],\n",
      "          [-4.6576e-01, -2.6064e-01, -1.3202e-01,  ..., -3.0610e-01,\n",
      "           -2.5514e-01, -2.6796e-01],\n",
      "          [-5.0990e-01, -3.1260e-01, -4.6426e-01,  ..., -2.0296e-01,\n",
      "           -2.0156e-01,  4.6045e-03],\n",
      "          ...,\n",
      "          [-6.5737e-01, -1.0672e-01, -5.0869e-01,  ..., -2.5749e-01,\n",
      "           -1.4776e-01, -4.0553e-01],\n",
      "          [-2.0982e-01, -3.3017e-01, -2.3444e-01,  ..., -1.7540e-01,\n",
      "            5.4401e-04,  4.2452e-02],\n",
      "          [-2.0818e-01, -3.6568e-01, -2.0000e-01,  ..., -1.8361e-01,\n",
      "           -2.0207e-01, -4.0980e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3946e-02, -7.1026e-02,  3.1116e-01,  ...,  1.2006e-01,\n",
      "            6.7462e-02,  4.0594e-02],\n",
      "          [-1.7246e-01,  2.7250e-01,  8.7884e-02,  ...,  3.9606e-01,\n",
      "            3.0888e-01, -1.7461e-01],\n",
      "          [-6.4659e-02,  6.5714e-02,  3.1445e-01,  ...,  2.6101e-01,\n",
      "            4.8690e-01,  2.8070e-01],\n",
      "          ...,\n",
      "          [ 2.1550e-02,  4.0447e-02,  2.1747e-01,  ...,  1.9531e-01,\n",
      "            2.1031e-01,  8.3326e-02],\n",
      "          [ 9.6333e-02,  2.8935e-02,  5.8611e-02,  ...,  8.3159e-02,\n",
      "            1.8997e-01, -7.9349e-02],\n",
      "          [ 1.8903e-01,  2.9194e-01,  5.5989e-02,  ...,  6.5619e-02,\n",
      "            1.3758e-01, -1.0663e-01]],\n",
      "\n",
      "         [[-6.9883e-02,  1.2737e-01, -9.6084e-02,  ..., -8.9404e-02,\n",
      "           -3.1199e-01, -1.7354e-01],\n",
      "          [-2.9383e-01, -7.9037e-02, -1.2171e-01,  ...,  1.4315e-02,\n",
      "           -3.8997e-01, -1.4968e-01],\n",
      "          [-4.7090e-01, -3.6191e-01, -2.9983e-01,  ..., -1.5260e-01,\n",
      "           -1.0244e-01, -2.9850e-02],\n",
      "          ...,\n",
      "          [-3.5547e-01, -9.6995e-02, -2.4336e-01,  ..., -5.3426e-01,\n",
      "           -2.3039e-01, -1.3706e-01],\n",
      "          [-2.5846e-01, -4.4564e-01, -8.2988e-02,  ...,  8.7514e-02,\n",
      "            5.4484e-02, -1.1928e-01],\n",
      "          [-1.1123e-01, -2.4734e-01,  7.1229e-02,  ...,  2.5378e-01,\n",
      "            1.4016e-01,  4.4101e-02]],\n",
      "\n",
      "         [[-1.6273e-02,  6.7854e-02, -5.8572e-02,  ..., -1.4323e-01,\n",
      "           -1.9437e-01, -2.1560e-01],\n",
      "          [ 1.6317e-01,  4.5552e-01,  9.0716e-02,  ..., -4.1584e-03,\n",
      "            2.2491e-01,  1.3310e-01],\n",
      "          [ 3.6980e-01,  5.2590e-01,  6.1232e-01,  ...,  5.5560e-01,\n",
      "            2.8442e-01,  2.7846e-01],\n",
      "          ...,\n",
      "          [ 5.6359e-01,  4.7647e-01,  7.1819e-01,  ...,  6.9153e-01,\n",
      "            3.8627e-01,  8.5488e-02],\n",
      "          [ 3.7359e-01,  3.4885e-01,  4.8469e-01,  ...,  6.4157e-01,\n",
      "            2.0155e-01,  2.7982e-01],\n",
      "          [ 3.4891e-01,  4.0337e-01,  4.5853e-01,  ...,  4.4518e-01,\n",
      "            6.4196e-01,  1.3117e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5453e-01,  2.6096e-01,  2.2907e-01,  ...,  1.3618e-01,\n",
      "            9.6163e-02,  2.1093e-01],\n",
      "          [-2.0601e-01, -3.4632e-03, -1.6917e-01,  ..., -1.5352e-01,\n",
      "            1.2643e-01, -2.5836e-01],\n",
      "          [-2.1417e-02, -2.9730e-01,  2.1322e-01,  ...,  5.4415e-02,\n",
      "           -1.9469e-01,  5.4853e-02],\n",
      "          ...,\n",
      "          [-1.3546e-02, -2.6389e-01, -1.7131e-01,  ...,  3.6954e-01,\n",
      "            1.9401e-02,  1.0221e-01],\n",
      "          [-4.8079e-02, -2.4387e-01, -1.7956e-01,  ...,  4.4351e-02,\n",
      "           -1.7980e-01, -3.2103e-01],\n",
      "          [-4.9172e-02, -3.6052e-01, -3.9578e-01,  ..., -1.5049e-01,\n",
      "           -1.3162e-01, -1.5166e-01]],\n",
      "\n",
      "         [[ 5.9774e-02, -8.6981e-02, -4.9821e-02,  ...,  2.5683e-02,\n",
      "            2.5265e-02, -7.2085e-02],\n",
      "          [-1.8298e-01, -1.9895e-01, -5.0104e-02,  ...,  5.5445e-02,\n",
      "           -1.2220e-01, -5.9907e-02],\n",
      "          [-1.3969e-01,  1.5673e-02, -2.8731e-01,  ..., -1.6513e-01,\n",
      "           -4.6379e-02,  1.8683e-01],\n",
      "          ...,\n",
      "          [ 4.3352e-02, -1.5890e-01, -1.2081e-01,  ...,  8.0032e-02,\n",
      "           -6.0377e-02,  9.2303e-02],\n",
      "          [ 2.3045e-02, -4.8853e-02,  3.0463e-02,  ..., -1.8050e-01,\n",
      "            6.5580e-02,  1.3377e-01],\n",
      "          [ 5.6309e-03, -1.4187e-01,  3.1475e-01,  ...,  9.2415e-03,\n",
      "           -1.3541e-01, -2.5630e-02]],\n",
      "\n",
      "         [[-1.4090e-01, -9.4639e-02, -1.1267e-01,  ..., -2.0542e-01,\n",
      "           -7.0191e-04, -3.1814e-02],\n",
      "          [-5.0227e-01, -2.5679e-01, -5.0444e-01,  ..., -1.1996e-01,\n",
      "           -2.5806e-01, -2.6700e-01],\n",
      "          [-4.1414e-01, -1.1316e-01, -4.5042e-01,  ..., -3.9040e-01,\n",
      "           -2.0764e-01,  1.9149e-01],\n",
      "          ...,\n",
      "          [-6.7689e-01, -1.2671e-01, -4.3515e-01,  ..., -5.2731e-01,\n",
      "            7.3589e-03,  1.9397e-02],\n",
      "          [-2.4130e-01, -1.9287e-01, -1.0430e-01,  ..., -2.7660e-01,\n",
      "           -1.1264e-02, -1.3714e-01],\n",
      "          [-2.3983e-01, -2.1378e-01, -1.6689e-01,  ..., -1.4769e-01,\n",
      "            1.6728e-02,  1.1373e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2733e-01,  4.9887e-02,  2.0133e-02,  ...,  1.1384e-01,\n",
      "            1.2857e-01,  1.5584e-01],\n",
      "          [-1.0979e-01,  1.0996e-01,  2.7075e-02,  ..., -3.4351e-02,\n",
      "            2.7211e-01, -3.1294e-02],\n",
      "          [ 1.5311e-01,  2.1225e-01,  3.0820e-01,  ...,  3.5828e-02,\n",
      "            2.3188e-01, -1.1399e-01],\n",
      "          ...,\n",
      "          [-1.4621e-01,  1.5096e-01,  2.1557e-01,  ...,  1.8306e-01,\n",
      "            3.3995e-01, -3.6242e-02],\n",
      "          [-4.1110e-03,  2.5501e-01, -2.1292e-01,  ..., -1.9072e-02,\n",
      "            1.3264e-01,  5.7956e-02],\n",
      "          [ 1.3908e-01,  3.7682e-01, -1.0402e-01,  ...,  6.3299e-02,\n",
      "            2.1468e-01,  4.1322e-02]],\n",
      "\n",
      "         [[-3.2020e-02, -1.8769e-02, -2.3323e-02,  ..., -2.0375e-01,\n",
      "           -2.9041e-01, -2.0563e-01],\n",
      "          [-9.7708e-02,  1.5369e-02,  1.6005e-02,  ..., -6.5640e-03,\n",
      "            3.9713e-02, -1.4912e-01],\n",
      "          [-3.9164e-01, -3.3447e-01, -1.6565e-01,  ..., -2.2898e-01,\n",
      "            1.2447e-01, -2.5702e-01],\n",
      "          ...,\n",
      "          [-3.8370e-01, -2.2219e-01, -4.5438e-01,  ...,  1.2612e-01,\n",
      "           -6.2171e-01, -1.9243e-01],\n",
      "          [-9.9891e-02, -3.6349e-01,  2.1981e-02,  ..., -2.6982e-01,\n",
      "            2.0276e-02, -5.8984e-02],\n",
      "          [-1.5975e-01,  9.0134e-02,  2.1022e-01,  ...,  2.7812e-02,\n",
      "           -1.2904e-01, -1.1338e-01]],\n",
      "\n",
      "         [[-4.1603e-02, -1.0566e-01,  5.7052e-02,  ..., -7.7299e-02,\n",
      "           -1.4366e-01, -1.5067e-01],\n",
      "          [ 7.7413e-02,  2.9042e-01,  3.2163e-01,  ...,  9.3730e-02,\n",
      "            2.1486e-01,  1.6345e-01],\n",
      "          [ 2.4321e-01,  1.8649e-01,  2.0199e-01,  ...,  2.4149e-01,\n",
      "            2.8573e-01,  1.1025e-01],\n",
      "          ...,\n",
      "          [ 5.2883e-01,  1.9179e-01,  3.2046e-01,  ...,  6.3495e-01,\n",
      "            3.8573e-01,  2.3342e-01],\n",
      "          [ 4.8897e-01,  4.3496e-01,  4.4809e-01,  ...,  6.4111e-01,\n",
      "            4.6250e-01,  2.4849e-01],\n",
      "          [ 3.9506e-01,  6.8229e-01,  5.2815e-01,  ...,  6.0257e-01,\n",
      "            3.5077e-01,  1.9938e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8503e-02,  3.7680e-02,  1.3494e-01,  ...,  2.7552e-01,\n",
      "            1.2623e-01,  1.1571e-01],\n",
      "          [-3.9611e-02, -6.5561e-02,  1.5602e-01,  ..., -2.4158e-01,\n",
      "            1.0340e-01, -1.2662e-01],\n",
      "          [-6.1398e-02, -3.6142e-01, -4.1653e-03,  ...,  1.8047e-01,\n",
      "           -1.7155e-02,  2.4871e-01],\n",
      "          ...,\n",
      "          [-6.7679e-02, -2.5448e-01,  9.3459e-02,  ...,  2.0464e-01,\n",
      "           -6.5089e-02, -1.9306e-01],\n",
      "          [-5.3029e-02, -6.7839e-01, -2.8068e-01,  ..., -4.4219e-01,\n",
      "           -2.1072e-01, -1.6061e-01],\n",
      "          [-2.7649e-01, -3.0307e-01, -3.2838e-01,  ..., -4.5148e-01,\n",
      "            3.9793e-02, -3.0763e-01]],\n",
      "\n",
      "         [[ 1.8373e-01, -2.2552e-01,  4.2006e-02,  ..., -1.7139e-01,\n",
      "            2.0064e-01, -8.6750e-02],\n",
      "          [-2.6347e-02, -3.8617e-02, -1.2418e-02,  ...,  6.7542e-05,\n",
      "           -1.3130e-01, -8.6351e-02],\n",
      "          [ 1.4029e-01, -4.7476e-01,  1.8486e-02,  ..., -1.1878e-01,\n",
      "            3.6527e-02,  7.5694e-02],\n",
      "          ...,\n",
      "          [-5.2862e-03,  6.9285e-02,  2.2334e-01,  ..., -1.5799e-01,\n",
      "            4.7047e-02,  2.2686e-01],\n",
      "          [-7.6796e-02, -2.6779e-01,  1.6643e-01,  ..., -2.0723e-01,\n",
      "           -2.1538e-01,  2.5911e-01],\n",
      "          [ 6.3243e-03,  8.3253e-02,  5.7537e-02,  ...,  1.1799e-01,\n",
      "           -8.8983e-02,  5.7018e-02]],\n",
      "\n",
      "         [[-1.3850e-01, -9.6795e-02, -1.5762e-01,  ..., -6.7797e-02,\n",
      "           -1.2025e-01,  1.5869e-02],\n",
      "          [-2.7117e-01, -1.9189e-01, -4.4971e-01,  ..., -3.9899e-01,\n",
      "           -4.1697e-01, -3.5072e-01],\n",
      "          [-4.6113e-01, -7.7353e-01, -2.5542e-01,  ..., -3.2703e-01,\n",
      "            9.3974e-02, -2.3278e-02],\n",
      "          ...,\n",
      "          [-2.3136e-01, -3.9745e-01, -3.9235e-01,  ..., -2.9178e-01,\n",
      "           -4.3108e-01,  8.1708e-02],\n",
      "          [-2.3230e-01, -2.8639e-01, -2.2199e-01,  ..., -3.5545e-01,\n",
      "            4.5792e-02, -5.5364e-02],\n",
      "          [-2.4900e-01, -3.7319e-01, -2.3507e-01,  ..., -1.5578e-01,\n",
      "            1.6093e-03, -1.0944e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.7866e-02,  6.1917e-02,  1.9615e-02,  ..., -2.4708e-02,\n",
      "            7.5154e-02, -9.1248e-03],\n",
      "          [-5.1394e-02, -5.9719e-02,  1.4627e-01,  ...,  3.1906e-02,\n",
      "            2.2507e-01, -1.2662e-01],\n",
      "          [ 5.4034e-02,  3.1527e-01,  4.2706e-01,  ...,  4.8638e-02,\n",
      "            5.2618e-01, -5.8506e-02],\n",
      "          ...,\n",
      "          [ 2.0718e-02,  2.9749e-01,  3.9758e-01,  ...,  3.0957e-01,\n",
      "            2.2499e-01,  5.0968e-02],\n",
      "          [ 1.8600e-01,  2.8566e-01, -9.5207e-03,  ..., -2.4802e-02,\n",
      "            3.3909e-01,  1.9471e-01],\n",
      "          [ 1.0596e-01,  7.3844e-02,  2.0186e-01,  ...,  7.1499e-02,\n",
      "            1.5706e-01, -2.4238e-01]],\n",
      "\n",
      "         [[ 2.8820e-02, -8.5024e-02, -2.2944e-01,  ..., -2.3088e-01,\n",
      "           -1.9476e-01, -2.1169e-01],\n",
      "          [-1.4486e-01,  1.8010e-01,  2.0391e-01,  ...,  9.1053e-02,\n",
      "           -6.5758e-02, -8.9202e-02],\n",
      "          [-4.8874e-01, -1.8763e-01, -5.1912e-01,  ..., -2.4311e-01,\n",
      "            1.1907e-02, -2.7146e-01],\n",
      "          ...,\n",
      "          [-3.0560e-01, -4.5171e-01, -9.0442e-02,  ..., -1.7541e-01,\n",
      "           -2.0056e-02, -1.7233e-01],\n",
      "          [-2.6651e-02, -2.7449e-01, -1.1579e-01,  ..., -7.0181e-02,\n",
      "            1.7410e-01, -8.5119e-02],\n",
      "          [-4.8340e-02, -9.7576e-02,  3.2661e-01,  ..., -1.9791e-01,\n",
      "            1.1684e-01, -1.1057e-01]],\n",
      "\n",
      "         [[-3.4362e-02, -5.4357e-02,  1.3996e-01,  ..., -8.7556e-02,\n",
      "           -7.9779e-02, -5.1132e-02],\n",
      "          [ 1.3707e-01, -4.1113e-02,  1.6633e-01,  ...,  2.0675e-01,\n",
      "            1.9932e-01,  6.5767e-02],\n",
      "          [ 3.6397e-01,  4.0120e-01,  4.9028e-01,  ...,  4.7751e-01,\n",
      "            3.9981e-01,  1.4455e-03],\n",
      "          ...,\n",
      "          [ 4.8693e-01,  5.2364e-01,  4.4323e-01,  ...,  6.5247e-01,\n",
      "            2.5685e-01,  3.1827e-01],\n",
      "          [ 3.3819e-01,  6.4336e-01,  4.2973e-01,  ...,  4.9833e-01,\n",
      "            6.5876e-01,  2.7189e-01],\n",
      "          [ 3.5864e-01,  4.8158e-01,  6.6019e-01,  ...,  6.6013e-01,\n",
      "            5.2601e-01,  2.2673e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.0923e-01,  4.9907e-02,  1.7752e-03,  ...,  7.7553e-02,\n",
      "            1.2441e-01,  1.8202e-01],\n",
      "          [-2.0813e-01, -3.9654e-01, -2.4421e-01,  ..., -1.0447e-01,\n",
      "           -1.8397e-01, -7.2985e-02],\n",
      "          [-1.9483e-02, -2.6630e-01, -8.0113e-02,  ...,  5.1476e-02,\n",
      "            1.7141e-01, -6.5963e-02],\n",
      "          ...,\n",
      "          [-3.0611e-02, -1.6097e-01,  1.1849e-01,  ...,  2.9249e-01,\n",
      "           -1.1281e-01,  1.0643e-01],\n",
      "          [-3.0795e-01, -2.4049e-01, -1.7993e-01,  ..., -3.3272e-02,\n",
      "           -3.2843e-01, -2.5720e-01],\n",
      "          [-2.2905e-01, -3.7100e-01, -2.6849e-02,  ..., -1.8769e-01,\n",
      "           -2.7444e-01, -2.9033e-01]],\n",
      "\n",
      "         [[-2.9934e-02, -1.1471e-01,  5.7967e-02,  ..., -1.4591e-01,\n",
      "            8.9359e-02, -6.6801e-02],\n",
      "          [ 6.0882e-02, -1.2612e-01, -2.1306e-02,  ..., -2.8787e-01,\n",
      "           -5.2693e-02, -1.9435e-01],\n",
      "          [ 2.5815e-01, -3.0730e-01,  2.9593e-01,  ..., -1.0865e-01,\n",
      "           -1.4454e-01,  2.5069e-01],\n",
      "          ...,\n",
      "          [ 1.4543e-01, -6.3561e-02,  1.0005e-01,  ...,  9.8558e-02,\n",
      "           -1.3286e-01,  2.1679e-01],\n",
      "          [-1.0227e-01, -2.7460e-02, -1.0009e-01,  ..., -4.9490e-02,\n",
      "           -1.7079e-02, -8.6171e-02],\n",
      "          [-6.0752e-02, -1.3901e-01, -5.4183e-02,  ..., -1.6269e-02,\n",
      "           -7.2292e-03,  2.0190e-01]],\n",
      "\n",
      "         [[-2.7477e-01, -4.3918e-02,  1.6837e-02,  ..., -1.6696e-01,\n",
      "           -5.3004e-02, -2.2150e-02],\n",
      "          [-4.6437e-01, -3.0387e-01, -4.9297e-01,  ..., -4.3197e-01,\n",
      "           -2.4389e-01, -6.1808e-02],\n",
      "          [-3.1118e-01, -4.8901e-01, -3.6131e-01,  ..., -4.1359e-01,\n",
      "            1.7862e-02, -5.0936e-02],\n",
      "          ...,\n",
      "          [-3.3030e-01, -5.1580e-01,  1.2069e-01,  ..., -2.8249e-01,\n",
      "           -1.4611e-01, -1.7070e-01],\n",
      "          [-1.9138e-01, -1.4300e-01, -2.8595e-01,  ..., -6.0298e-02,\n",
      "           -1.3719e-01, -6.6971e-02],\n",
      "          [-2.8744e-01, -2.3514e-01, -3.2579e-01,  ..., -2.1015e-01,\n",
      "           -5.4162e-03, -2.1588e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4813e-02,  1.1399e-02,  2.0114e-03,  ...,  1.4019e-01,\n",
      "            8.4737e-02,  1.3321e-02],\n",
      "          [ 3.9865e-02, -4.0622e-02,  9.7025e-02,  ...,  7.7097e-02,\n",
      "            2.9772e-01,  1.3354e-01],\n",
      "          [ 1.2620e-01,  1.7637e-01,  1.3955e-01,  ...,  1.3956e-01,\n",
      "            3.1629e-01,  1.9030e-02],\n",
      "          ...,\n",
      "          [-1.1605e-01,  3.5449e-01,  2.0013e-01,  ...,  1.6315e-01,\n",
      "            1.5614e-01,  2.4647e-01],\n",
      "          [ 1.5491e-01,  2.4502e-01,  2.4826e-01,  ...,  1.9087e-01,\n",
      "            2.2692e-01, -4.5380e-02],\n",
      "          [ 6.5096e-02, -3.2267e-02,  4.6196e-02,  ...,  2.0181e-01,\n",
      "           -7.1557e-02, -6.2233e-02]],\n",
      "\n",
      "         [[ 1.2634e-01, -1.2280e-01, -2.4829e-01,  ..., -2.3113e-01,\n",
      "           -2.6059e-01, -2.0415e-01],\n",
      "          [-7.4210e-03, -5.9565e-02, -1.9320e-02,  ..., -2.0559e-01,\n",
      "           -9.7348e-02, -9.5290e-02],\n",
      "          [-1.1471e-01, -5.4842e-01, -3.0545e-01,  ..., -2.8509e-01,\n",
      "           -1.5752e-01, -8.4757e-02],\n",
      "          ...,\n",
      "          [-4.4252e-02, -1.0493e-01, -1.5007e-01,  ..., -2.3468e-01,\n",
      "           -3.2627e-01, -4.9536e-01],\n",
      "          [-1.8087e-01, -2.8305e-01,  1.2906e-01,  ...,  7.5352e-02,\n",
      "           -1.0446e-01, -1.8638e-01],\n",
      "          [-4.6223e-01, -2.2175e-01,  2.3922e-03,  ..., -1.0618e-01,\n",
      "            1.1610e-01, -1.3581e-01]],\n",
      "\n",
      "         [[-5.5989e-02, -1.0739e-01, -1.7824e-01,  ..., -1.5869e-01,\n",
      "           -7.3201e-02, -1.0945e-01],\n",
      "          [ 2.1439e-01,  2.1553e-01,  2.0003e-01,  ...,  5.7432e-02,\n",
      "            1.3810e-01,  1.4419e-02],\n",
      "          [ 3.5522e-01,  3.9198e-01,  3.5255e-01,  ...,  5.0360e-01,\n",
      "            3.4661e-01,  3.3735e-01],\n",
      "          ...,\n",
      "          [ 3.1789e-01,  4.5855e-01,  5.1950e-01,  ...,  5.3043e-01,\n",
      "            3.0016e-01,  4.0133e-01],\n",
      "          [ 5.8205e-01,  6.3090e-01,  2.4854e-01,  ...,  5.1567e-01,\n",
      "            4.5439e-01,  5.4967e-02],\n",
      "          [ 5.1029e-01,  5.4422e-01,  6.0825e-01,  ...,  5.9610e-01,\n",
      "            4.6659e-01,  1.9415e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1939e-01,  5.6407e-03,  1.8083e-01,  ...,  2.0074e-01,\n",
      "            2.2793e-01,  1.6221e-02],\n",
      "          [-6.2215e-02, -3.0538e-01, -1.3565e-01,  ..., -1.4721e-01,\n",
      "           -2.9298e-01, -1.7864e-01],\n",
      "          [-1.0170e-01, -3.4716e-01,  1.0498e-01,  ...,  2.2943e-01,\n",
      "            2.3171e-02,  1.1428e-01],\n",
      "          ...,\n",
      "          [-1.6434e-01, -2.0207e-01, -3.8416e-01,  ..., -1.5695e-01,\n",
      "            5.6319e-02,  6.7022e-02],\n",
      "          [-1.8819e-01, -2.6771e-01, -1.3717e-01,  ..., -1.8084e-01,\n",
      "           -1.5574e-01,  2.2047e-02],\n",
      "          [-3.0788e-01, -1.4881e-01, -4.4244e-02,  ..., -4.5370e-01,\n",
      "           -5.9066e-02, -4.0386e-01]],\n",
      "\n",
      "         [[ 9.6523e-02, -1.4884e-01, -7.9676e-02,  ..., -5.4507e-02,\n",
      "           -9.0182e-02,  4.0543e-02],\n",
      "          [-1.8129e-01, -2.9853e-01, -2.4775e-01,  ..., -5.5866e-03,\n",
      "            1.8654e-01, -1.5791e-01],\n",
      "          [-9.0717e-02, -7.2089e-02,  4.1422e-01,  ..., -5.8651e-02,\n",
      "           -1.4341e-02, -8.2802e-02],\n",
      "          ...,\n",
      "          [ 7.6563e-02, -1.2477e-01, -5.4788e-01,  ...,  1.5835e-02,\n",
      "            1.0310e-01,  1.1566e-01],\n",
      "          [-1.2610e-01, -1.2398e-01, -4.2457e-02,  ...,  1.7294e-01,\n",
      "           -2.8155e-02,  1.7591e-01],\n",
      "          [-8.3024e-02, -8.6497e-02, -1.5240e-02,  ...,  1.1667e-01,\n",
      "            4.8424e-02, -8.7068e-02]],\n",
      "\n",
      "         [[-1.5489e-01, -4.5651e-02,  1.0478e-02,  ..., -1.6863e-01,\n",
      "           -1.8775e-01, -6.4087e-03],\n",
      "          [-3.5932e-01, -1.8253e-01, -3.3018e-01,  ..., -1.4684e-01,\n",
      "           -4.8682e-01, -2.7102e-01],\n",
      "          [-3.6266e-01, -6.0490e-01, -1.2610e-01,  ..., -2.1209e-01,\n",
      "           -1.4180e-01, -1.1306e-01],\n",
      "          ...,\n",
      "          [-4.1170e-01, -3.6352e-01, -3.7099e-01,  ..., -3.7812e-01,\n",
      "           -2.2409e-01,  1.5965e-02],\n",
      "          [-1.7018e-01, -2.9369e-01, -1.0627e-01,  ..., -2.0735e-01,\n",
      "            8.0213e-03, -2.0076e-01],\n",
      "          [-3.5480e-01, -3.5718e-01, -2.4284e-01,  ..., -1.1020e-01,\n",
      "            4.9366e-03, -1.7458e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2912e-01,  2.0627e-01, -1.2177e-01,  ...,  8.4251e-02,\n",
      "            2.7295e-01,  8.0878e-02],\n",
      "          [-1.0468e-01,  8.8218e-02,  4.5853e-02,  ...,  4.3889e-02,\n",
      "            2.8443e-01, -1.2997e-01],\n",
      "          [-4.8586e-02,  8.3388e-02,  2.3244e-01,  ...,  2.6459e-01,\n",
      "            2.1098e-01,  2.7017e-02],\n",
      "          ...,\n",
      "          [ 2.3421e-01,  2.4114e-01,  2.4769e-01,  ...,  1.4185e-01,\n",
      "            8.1979e-02,  1.1917e-01],\n",
      "          [ 2.0522e-01,  9.2765e-02,  2.3970e-01,  ..., -8.6615e-03,\n",
      "           -9.1484e-04, -2.2794e-01],\n",
      "          [ 2.5915e-02,  5.0050e-01, -3.6510e-02,  ..., -6.0340e-02,\n",
      "            1.6040e-01, -3.0711e-02]],\n",
      "\n",
      "         [[ 1.2410e-02, -1.3117e-01, -4.5044e-01,  ..., -1.9141e-01,\n",
      "           -7.2656e-02, -2.2281e-01],\n",
      "          [-5.9057e-02, -9.9754e-02, -7.7831e-02,  ..., -4.3789e-02,\n",
      "           -1.5066e-02, -1.4054e-01],\n",
      "          [-3.4300e-01, -1.1705e-01, -1.8725e-01,  ..., -1.3123e-01,\n",
      "           -9.8395e-02, -3.4443e-01],\n",
      "          ...,\n",
      "          [-4.9073e-02, -3.9044e-01,  3.8278e-02,  ..., -2.3577e-01,\n",
      "           -3.1065e-01, -1.1848e-01],\n",
      "          [-1.9283e-01, -4.1983e-01, -2.5264e-02,  ..., -7.9158e-02,\n",
      "            2.4064e-01,  7.3811e-02],\n",
      "          [-1.4875e-01, -1.6627e-01,  2.2666e-01,  ...,  2.6731e-01,\n",
      "            2.1532e-01, -8.6536e-02]],\n",
      "\n",
      "         [[-1.0420e-01, -9.8995e-02, -9.3193e-02,  ..., -1.4659e-01,\n",
      "           -1.0266e-01, -1.3034e-01],\n",
      "          [ 3.0459e-01,  2.6987e-01,  2.8643e-01,  ...,  1.2264e-01,\n",
      "            2.0693e-01,  9.7325e-02],\n",
      "          [ 3.4375e-01,  1.3750e-01,  2.4043e-01,  ...,  4.2121e-01,\n",
      "            4.5911e-01, -1.0969e-01],\n",
      "          ...,\n",
      "          [ 2.9842e-01,  5.0730e-01,  3.4886e-01,  ...,  4.6815e-01,\n",
      "            3.4380e-01,  1.7319e-02],\n",
      "          [ 3.3882e-01,  5.5558e-01,  4.9967e-01,  ...,  5.5756e-01,\n",
      "            3.0640e-01,  1.0208e-01],\n",
      "          [ 5.0496e-01,  3.9702e-01,  6.0773e-01,  ...,  5.0631e-01,\n",
      "            3.8106e-01,  2.4642e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4270e-01,  1.5097e-01,  2.8042e-01,  ...,  2.1730e-01,\n",
      "            2.4104e-01,  4.0499e-02],\n",
      "          [ 4.7903e-02, -3.0050e-01, -9.3700e-02,  ..., -2.5313e-01,\n",
      "            1.3348e-02, -1.5419e-01],\n",
      "          [ 2.3310e-01, -1.4424e-01, -3.1330e-01,  ..., -2.4238e-01,\n",
      "            1.6505e-01,  1.5470e-01],\n",
      "          ...,\n",
      "          [-1.0661e-01, -6.4020e-02, -2.8169e-01,  ..., -1.0157e-01,\n",
      "           -1.9157e-01, -4.2773e-02],\n",
      "          [-3.1194e-01, -2.9266e-01, -3.3531e-01,  ..., -6.6375e-02,\n",
      "           -1.6956e-01, -7.7609e-02],\n",
      "          [-1.9917e-01, -2.2664e-01, -2.1705e-01,  ..., -1.5973e-01,\n",
      "           -1.4800e-01, -1.4411e-01]],\n",
      "\n",
      "         [[-7.9493e-02, -6.8730e-02, -7.8253e-02,  ..., -7.3267e-02,\n",
      "            1.0542e-01, -9.6991e-02],\n",
      "          [-1.4593e-01, -3.1732e-01,  7.9878e-02,  ...,  1.3470e-01,\n",
      "           -2.4618e-02, -2.1410e-01],\n",
      "          [ 2.5988e-02, -2.3894e-01,  3.0694e-01,  ...,  1.1906e-01,\n",
      "            1.9003e-02,  2.1492e-02],\n",
      "          ...,\n",
      "          [ 1.3059e-01, -1.7056e-01, -7.3426e-02,  ..., -8.0531e-02,\n",
      "            2.2362e-01,  9.2103e-02],\n",
      "          [-2.1044e-02,  5.0714e-02,  5.4581e-02,  ...,  4.0626e-03,\n",
      "            1.2594e-02, -7.7386e-02],\n",
      "          [-1.0061e-01, -1.7643e-01, -1.4118e-01,  ...,  1.0095e-01,\n",
      "           -6.1987e-02,  6.6365e-02]],\n",
      "\n",
      "         [[-1.1822e-01, -4.9292e-02,  1.0423e-02,  ..., -2.8653e-01,\n",
      "           -9.5024e-02, -5.2693e-02],\n",
      "          [-5.0231e-01, -2.0502e-01, -1.7914e-01,  ..., -2.6827e-01,\n",
      "           -5.4896e-01, -1.5794e-01],\n",
      "          [-4.1711e-01, -3.8708e-01, -4.9741e-01,  ..., -2.9020e-01,\n",
      "           -3.5928e-01,  2.5971e-01],\n",
      "          ...,\n",
      "          [-4.2193e-01, -6.6867e-01, -9.4076e-02,  ..., -1.5034e-01,\n",
      "           -1.0736e-01, -6.6918e-02],\n",
      "          [-2.2276e-01, -2.8175e-01, -2.3696e-01,  ..., -1.0538e-01,\n",
      "           -3.4081e-02, -1.5327e-01],\n",
      "          [-8.2674e-02, -3.7258e-01, -7.7638e-02,  ..., -1.8633e-01,\n",
      "           -3.7750e-02, -6.4398e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.1821e-03,  3.7650e-02, -6.5238e-02,  ...,  2.7898e-01,\n",
      "            1.2307e-01, -2.2152e-02],\n",
      "          [ 1.8160e-02,  3.0893e-02,  2.8582e-01,  ...,  8.5571e-02,\n",
      "            1.9280e-01,  4.2402e-02],\n",
      "          [ 2.7399e-01,  3.5074e-01,  2.0416e-01,  ...,  1.9087e-01,\n",
      "            2.6441e-01, -2.7536e-02],\n",
      "          ...,\n",
      "          [ 1.2181e-01,  1.4047e-01,  4.7817e-01,  ...,  3.0724e-01,\n",
      "            1.8444e-01,  7.0517e-02],\n",
      "          [ 8.6746e-02,  1.5696e-01,  3.0711e-02,  ...,  1.8672e-01,\n",
      "            4.9726e-02,  6.3986e-02],\n",
      "          [ 1.1453e-01,  1.9607e-01,  9.1739e-02,  ...,  1.9157e-01,\n",
      "            6.1245e-02,  7.0122e-02]],\n",
      "\n",
      "         [[ 3.8333e-02, -1.0583e-01, -2.3575e-01,  ..., -2.8472e-02,\n",
      "           -2.4608e-01, -1.0049e-01],\n",
      "          [-8.5299e-02,  6.2911e-02, -7.1290e-02,  ..., -3.3972e-02,\n",
      "            1.5465e-02, -2.4011e-01],\n",
      "          [-1.4281e-01, -1.5086e-01, -1.6306e-01,  ..., -9.0383e-02,\n",
      "           -2.1873e-01,  1.4451e-01],\n",
      "          ...,\n",
      "          [ 8.5719e-03, -3.5420e-01, -1.8256e-01,  ..., -2.5843e-01,\n",
      "           -3.2703e-01,  1.6769e-03],\n",
      "          [-2.4515e-01, -2.6532e-01,  9.9880e-02,  ..., -8.3170e-03,\n",
      "           -6.3183e-02, -1.9291e-01],\n",
      "          [-2.6617e-01, -2.9542e-01,  7.7079e-02,  ...,  2.5469e-01,\n",
      "           -1.3648e-01,  5.5943e-02]],\n",
      "\n",
      "         [[ 4.3152e-02, -6.6662e-02, -2.1589e-01,  ..., -1.4424e-01,\n",
      "            6.8574e-02, -2.1220e-01],\n",
      "          [ 1.7373e-01,  1.8231e-01,  3.1810e-01,  ...,  3.1097e-01,\n",
      "            1.5308e-01,  4.0241e-02],\n",
      "          [ 5.3197e-01,  4.6821e-01,  2.7396e-01,  ...,  6.4003e-01,\n",
      "            6.1159e-02,  7.2597e-02],\n",
      "          ...,\n",
      "          [ 2.8615e-01,  1.0858e-01,  9.2397e-01,  ...,  4.0681e-01,\n",
      "            2.1127e-01,  1.8214e-01],\n",
      "          [ 4.3193e-01,  4.1148e-01,  6.4429e-01,  ...,  4.6122e-01,\n",
      "            3.9948e-01,  1.6014e-01],\n",
      "          [ 5.4996e-01,  3.3997e-01,  4.3527e-01,  ...,  4.0477e-01,\n",
      "            3.8771e-01,  4.1697e-01]]]], grad_fn=<MkldnnConvolutionBackward>)\n"
     ]
    }
   ],
   "source": [
    "m = nn.Conv2d(16,33,3,stride=2)\n",
    "\n",
    "m = nn.Conv2d(16,33,(3,5),stride=(2,1),padding=(4,2))\n",
    "\n",
    "m = nn.Conv2d(16,33,(3,5),stride=(2,1),padding=(4,2), dilation=(3,1))\n",
    "\n",
    "input = torch.rand(20,16,50,100)\n",
    "print(input)\n",
    "output = m(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 33, 26, 100])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.functional 패키지\n",
    "- 가중치를 직접 선언하여 인자로 넣어줘야함\n",
    "- 예시) \n",
    "    - Convolution Functions\n",
    "    - Pooling Functions\n",
    "    - Non-linear activation Functions\n",
    "    - Normalization Functions\n",
    "    - Linear Functions\n",
    "    - Dropout Functions\n",
    "    - Sparse Functions\n",
    "    - Distance Functions\n",
    "    - Loss Functions\n",
    "    - ..\n",
    " - https://pytorch.org/docs/stable/nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convolutiob Layer 예시 (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = torch.randn(8,4,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 5, 5])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(1,4,5,5)\n",
    "conv = F.conv2d(inputs, filters, padding=1)\n",
    "conv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torchvision\n",
    "- transforms : 전처리할 때 사용하는 메소드\n",
    "- transforms에서 제공하는 클래스 이외에 일반적으로 클래스를 따로 만들어 전처리 단계를 진행\n",
    "    - 아래의 코드에서 다양한 전처리 기술 확인\n",
    "    - https://pytorch.org/docs/stable/torchvision/transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/6f/7e3e9e51c770e83046699e4a4842712471a96c7aefe83054b7c9087c20b1/torchvision-0.8.1-cp37-cp37m-macosx_10_9_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 2.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/psh/opt/anaconda3/lib/python3.7/site-packages (from torchvision) (1.17.2)\n",
      "Requirement already satisfied: torch==1.7.0 in /Users/psh/opt/anaconda3/lib/python3.7/site-packages (from torchvision) (1.7.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Users/psh/opt/anaconda3/lib/python3.7/site-packages (from torchvision) (6.2.0)\n",
      "Requirement already satisfied: dataclasses in /Users/psh/opt/anaconda3/lib/python3.7/site-packages (from torch==1.7.0->torchvision) (0.6)\n",
      "Requirement already satisfied: future in /Users/psh/opt/anaconda3/lib/python3.7/site-packages (from torch==1.7.0->torchvision) (0.17.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/psh/opt/anaconda3/lib/python3.7/site-packages (from torch==1.7.0->torchvision) (3.7.4.3)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예시)\n",
    "    - DataLoader의 인자로 들어갈 transform을 미리 정의할 수 있음\n",
    "    - Compose를 통해 리스트 안에 순서대로 전처리 진행\n",
    "    - 대표적인 예로, ToTensor()를 하는 이유는\n",
    "    - torchvision이 PIL Image형태로만 입력을 받기 때문에 데이터 처리를 위해서 Tensor형으로 변환해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize(mean=(0.5,),std=(0.5,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils.data\n",
    "- Dataset에는 다양한 데이터셋이 존재\n",
    "    - MNIST, CIFAR10 ...\n",
    "- DataLoader, Dataset을 통해 batch_size, train여부, transform등을 인자로 넣어 데이터를 어떻게 load할 것인지 정해줄 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./content/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f9e22c3636405dacc116f4a755aff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./content/MNIST/raw/train-images-idx3-ubyte.gz to ./content/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./content/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8059610015cb4ca0b57011148b4a7019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./content/MNIST/raw/train-labels-idx1-ubyte.gz to ./content/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./content/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2fd991226e4e608bf7ebd049110211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./content/MNIST/raw/t10k-images-idx3-ubyte.gz to ./content/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./content/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4cd1c6ec1f041b8a80e2f2e2a58d60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./content/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./content/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/psh/opt/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.MNIST(root = './content/',\n",
    "                                     train=True,\n",
    "                                     download=True,\n",
    "                                     transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root = './content/',\n",
    "                                     train=False,\n",
    "                                     download=True,\n",
    "                                     transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=8,shuffle=True,num_workers=2)\n",
    "test_loader = DataLoader(testset, batch_size=8,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch_size만큼 데이터를 하나씩 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1, 28, 28]), torch.Size([8]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images.shape, labels.shape #torch size의 1이 채널값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(중요) torch에서는 channel(채널)이 앞에 옴**\n",
    "- channel first\n",
    "- tensorflow, keras등에서는 channel이 뒤에 옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_image = torch.squeeze(images[0])\n",
    "torch_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch_image.numpy()\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = labels[0].numpy()\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(7)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(label)\n",
    "plt.imshow(image,'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 Layer 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Conv2d\n",
    "- in_channels : 채널의 개수\n",
    "- out_channels : 출력 채널의 개수\n",
    "- kernel_size : 커널(필터) 사이즈\n",
    "- 텐서플로우, 케라스와 다르게 레이어의 input 인자에도 값을 집어 넣어줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Conv2d(1,20,5,1).to(torch.device('cpu'))\n",
    "layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- weight 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 5, 5])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = layer.weight\n",
    "weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- weight는 detach()를 통해서 꺼내줘야 numpy() 변환이 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = weight.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1, 5, 5)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = weight.numpy()\n",
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(weight[0,0,:,:],'jet')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.unsqueeze(images[0],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = layer(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 24, 24])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_arr = output.numpy()\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2IAAAEfCAYAAAAjjHWkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5SddX3v8XcuBCRMAiThIuFa4ldRFOQqCkQB24iWFG2tPaKiHo49uhYeXXiFek6P1UMXUo8i2KJUi0qt0KjURmNFRFCqRKqEyzeSCJLD1ZhMEpIQJpnzx96pkzCZ/cvMnufZe+f9Wsvlvnzm+X1nT/bD831+z2XC4OAgkiRJkqTqTKy7AEmSJEna1diISZIkSVLFbMQkSZIkqWI2YpIkSZJUMRsxSZIkSaqYjZgkSZIkVcxGTM8QEQ9ExPHjsNy/iIhz2r1cSb0lIr4dERcOef6ciBiMiI8NeW2/iHgqIqbvYBnPjogfFYy1w/VdRCyKiJmj+R0k9baIeEdE/Dwi7omIuyPi2og4pODnro6I48Yw7vSIuGm0P6/OYiOmKr0C2K3uIiR1vIXAy4c8fw1wIzB0R84rgNsys3+4BWTmw5l5yhjrOGuMPy+pB0XEZcBrgVdn5lHA0cB3gR9HxOwWP34WMGEMw+8DnDiGn1cHmeANnbW9iHgAeB1wK/B/gFcCBwJ/nZlXRcRbgD+m0cgfCvw/4M2Z+XBE3AxckZnXN5d1M3AFsD9wKfAE8J7MXFDdbySpm0TEc4DbgZmZuaW5HvkQ8I/AyzNzWURcDdzXfO0K4BAaO3r+MTM/FhGHAUsyc6+I2BP4LHAysBq4ByAz39Jc330XOBbYD7g2Mz8cEX8PvAVYArwqMx+q4neX1NmajdZ9wMGZuWq79/4vMBk4G3hdZt7RfP0BGttVfwRcBPwKeBON7aKfAS8DZtJY/3xk6Pqr+fP/+Twivg+cBtwFHJeZm8fz99X4ckZMI9kd+E1zr/LrgL+JiD2a750OXNjcE7QY+NRIC8rMzwB3ABfZhEkaSWYuBVYBL4yIfYCg0Zj9K/CHzdgZwLeAa4FrMvM4GnuJz4yIP9lukZfQ2Dh6LnAmjaZrqI2ZeXzz598bEQdn5vnN915uEyZpiJOAe7dvwpr+jUZTNazM/DDwMPBfMvPfmy8H8FLgxcDrI+LVLcY/H9iQmcfYhHU/GzG18o3m//+MRmM2tfl8UXNjCeBq4PerLkxST1sIzAXmAd/NzC3AvwCvbO4dHgQeorFT6H9HxH/QaNYOAY7ZblmvAj6fmVsycw3wxe3e/wpAZj4KPEZjZkySdmRHp1nsTmPdtDP+NjOfzszVwNdwe2qXYiOmVjYAZObWFcvW45oHhmQmAlv3ygyy7bHPU8a1Okm9aiGNw29eTaMBA/gejdmsM2nMhk2isb45pbl3+Bgahx9+bLtlDbDtemn7vchPD3m8/TpMkoa6HZgTEQcM897LgR+xc9tCw21PuS21i7AR02idEREHNR+/g8aJ9NA4B+x4gIg4CnjhkJ8ZwIt1SCrzfRozW6cD3wHIzA00DoV+F/Ct5uzW7cB7ACJib+A2tr2oBzSatvMjYmLzfLE/o2yv9WZcZ0kaIjP/H43TMa4bsh1ERJxP4wIeW8+H37otNJfGefZbbb8t9Mbmumkf4E9obE+tBqY0t6MA3rDdz0+KCHcY9QAbMY3WCuDaiLgXOAx4d/P1j9I4dGgJ8JfALUN+5pvAxyPizVUWKqn7ZOZ64JeNh9tcGfFbwBzg5ubzPwNOjoi7gH8HrsvML2+3uI8DG2mc3P5vwOPA+oIyvgb8ICJeMNrfQ1LvycwPAl8CvhERSyLilzRm6l+SmQ8C7wcubB4yfR6NHUhb/TPwpYh4ZfP5s4Cf0NipdGVmfq+5znsfsDAifkrz6KSmR5r5uyNixvj9lqqCV03UTmteNfF1mdnqhFJJql1E/CmwJjP/NSImAjfQOM/1qppLk7QL2/5K09r1OCMmSep1S4APN/dOL6Fx1bLP1VuSJGlX54yYJEmSJFXMGTFJkiRJqpiNmCRJkiRVbPJ4LDQidgdOoHFlF+/6LfWGSTQuwfvTzHyq7mJGw3WT1JO6ft0Erp+kHjXi+mlcGjEaK5IfjtOyJdXrVODWuosYJddNUu/q5nUTuH6Setmw66dRNWLNy/9eCbwIeAp4e2bePyTyCMCvf/1rBgYGhlmCpG4zefJkDjnkEGh+v7tUY9205ssMbDmg7lpG7VdXHl53CW1x+J9eXXcJY3fr3LorGLMLXzan7hLGZP3kyXyv+9dN0Kz/ggsuYPr06XXXIqkN+vv7+bu/+zvYwfpptDNi84E9MvMlEXEy8AngnCHvbwYYGBiwEZN6TzcfMtNYN205gIEts+uuZdRmz+yN9erAwL51lzB2BxxUdwVjtlfv/He6o9dNBTuxNwNMnz6dffbZp4YKJY2jYddPo71Yx8uAbwNk5u3A8aNcjiRJ0q7gP3diAx+gsRNb0i5stI3YNKB/yPPNETFe55tJkiR1O3diS9rGaBuxNUDf0OVkZs8c2yBJktRm7sSWtI3RNmK3Aa8CaJ4jdlfbKpIkSeo97sSWtI3RNmILgI0R8SPgb4D/0b6SJEmSeo47sSVtY1RT4pm5BXhHm2uRJEnqVQuAs5o7sScA59dcj6SaeWyyJEnSOHMntqTtjfbQREmSJEnSKNmISZIkSVLFbMQkSZIkqWI2YpIkSZJUMRsxSZIkSaqYjZgkSZIkVcxGTJIkSZIqZiMmSZIkSRWzEZMkSZKkitmISZIkSVLFbMQkSZIkqWKT6y5AktopIiYCVwIvAp4C3p6Z99dblSRJ0racEZPUa+YDe2TmS4APAJ+ouR5JkqRnsBGT1GteBnwbIDNvB46vtxxJkqRnshGT1GumAf1Dnm+OCA/DliRJHcVGTFKvWQP0DXk+MTMH6ipGkiRpODZiknrNbcCrACLiZOCuesuRJEl6Jg/XkdRrFgBnRcSPgAnA+TXXI0mS9Aw2YpJ6SmZuAd5Rdx2SJEkj8dBESZIkSaqYM2KSJEldZN26dcXZzZs3F+WOPPLIotxRRx1VlOvv728davre975XlFuxYkVR7vnPf37x2JMnuyms+jgjJkmSJEkVsxGTJEmSpIrZiEmSJElSxWzEJEmSJKliNmKSJEmSVDEbMUmSJEmqmI2YJEmSJFXMRkySJEmSKmYjJkmSJEkV83bikiRJXWTjxo3F2ccff7wo9/DDDxflli5dWpQ744wzinIAr33ta4tyDz30UFFuyZIlxWNPmjSpKDc4OFiUe+yxx4pyBx54YFFOvc0ZMUmSJEmqmI2YJEmSJFXMRkySJEmSKmYjJkmSJEkVG/XFOiLiTqC/+fRXmXl+e0qSJEmSpN42qkYsIvYAyMy5ba1GkiRJknYBo50RexGwZ0Qsai7jQ5l5e/vKkiRJkqTeNdpGbD1wGfA5YA6wMCIiMwfaVpkkjZe/AWbUXcTo/bfTP1l3CW3xEc6pu4Qx+1//UnZvoU72P++tu4KxWfEY3HhB3VVI0s4bbSO2FLg/MweBpRGxEjgQKLvTniRJkiTtwkbbiL0VOBr47xHxbGAa8EjbqpIkSdKwVq1aVZxdtGhRUW7SpElFuYgoyr3whS8sygHcfffdRbmNGzcW5Y455pjisX/7298W5aZPn16UO+KII4pyO/M3rNP+++9flHv00UeLcv39/a1DTYsXLy7Klf6b7OvrKx67KqNtxD4PfCEibgUGgbd6WKIkSZIklRlVI5aZm4A/a3MtkiRJkrRLGPV9xCRJklTOe7BKGspGTJIkaZx5D1ZJ27MRkyRJGn/eg1XSNibWXYAkSdIuYOs9WH8feAfw5Yhwh7i0C3MFIEmSNP68B6ukbTgjJkmSNP7eCnwCwHuwSgJnxCRJkqrgPVglbcNGTJIkaZx5D1ZJ27MRa3rb297WMvO5z32uZebmm29umZk/f/6I7/f394/4viRJ2nXtu+++xdmjjz66KPfEE08U5davX1+Uu+GGG4pyALfccktR7vDDDy/KHXfcccVjH3HEEUW5hx9+uCi3YsWKotzO/A0HBweLco8//nhRbq+99ioeu/Tv/fznP78oN3Fi+VlRs2bNKsr94he/KMr19fUVj10VzxGTJEmSpIrZiEmSJElSxWzEJEmSJKliNmKSJEmSVDEbMUmSJEmqmI2YJEmSJFXMRkySJEmSKmYjJkmSJEkV84bOTZMnt/4otmzZ0jJz2mmntcz8+Mc/HvH9z3zmMy2XsXbt2paZknq/9KUvtcxIkiRJai8bMUk9JyJOAi7NzLl11yJJ7XbCCScUZ48++uii3M9//vOi3O23316Ue9aznlWUg7Kd4QDXXXddUe7rX/968dhz5swpzpaYMmVKUa6vr694mXvttVdR7sEHHyzKHXTQQcVj/8Ef/EFR7vDDDy/KDQwMFI+9ePHiotx+++1XvMxOYyMmqadExPuA84An665FkiRpRzxHTFKvWQacW3cRkiRJI7ERk9RTMvMG4Om665AkSRqJjZgkSZIkVcxGTJIkSZIqZiMmSZIkSRXzqolN//RP/9Qy8/rXv75lpuSSoPvuu++I719++eUtl1F6qddWrrrqqrYsp9ecfvrpLTM/+9nPKqhEo5GZDwAn112HJEnSjjgjJkmSJEkVsxGTJEmSpIp5aKIkSVIXGRgYKM6ecMIJRbmJE8v2zR9//PFFuV/84hdFOYBZs2YV5f7qr/6qKLdkyZLisV/ykpcU5W655Zai3MEHH1yUK/2dAQYHB4tys2fPLsrttddexWOvXLmyKNff31+U27BhQ/HYu+22W1Gu9N/aSSedVDx2VZwRkyRJkqSK2YhJkiRJUsVsxCRJkiSpYjZikiRJklQxGzFJkiRJqphXTWxatWpVy8wrXvGKtozV6qo28+fPb7mMiy66aMzjAOy5554tM+3w0EMPtcz85je/aZlZvnx5y8zZZ5/dMrPHHnuM+P4b3vCGlsvwhs6SJEkaLWfEJEmSJKliRTNiEXEScGlmzo2II4EvAIPAEuCdmbll/EqUJEmSpN7SckYsIt4HfA7YeizX5cDFmXkqMAE4Z/zKkyRJkqTeU3Jo4jLg3CHPjwN+0Hy8EDiz3UVJkiRJUi9reWhiZt4QEYcNeWlCZg42H68Fpo9HYZIkSXqmRx55pDg7a9asolxfX19R7v777y/KzZkzpygHMG/evKJcqwttbXXwwQcXj33kkUcW5Y4//viiXMnFyQCeeuqpotzOLHPlypVFuWXLlhWPPWnSpKLcgQceWJSbMWNG8di33XZbUe6YY44pXmanGc3FOoaeD9YHrG5TLZIkSZK0SxhNI3ZnRMxtPp4H/LB95UiSJElS7xvNfcTeC1wdEVOAe4Hr21uSJEmSJPW2okYsMx8ATm4+XgqcPo419bwVK1aM+P4VV1zRchlf/OIXW2Z233334prGW8mx0AMDAy0zGzZsaJkpOZb62c9+9ojv33PPPS2XIUmSJI2WN3SWJEmSpIqN5tBESepub74DBh6ou4pRez7vrruEtrjwssHWoQ534zvPqLuEMZsw4SN1lzAmkyev44gjbqy7DEnaac6ISZIkSVLFbMQkSZIkqWI2YpIkSZJUMc8RkyRJ6iJPP/10cXbx4sVtHbv0isyTJk0qXubs2bOLcrNmzSrK3XXXXcVjT5kypSh3ww03FOX6+vqKco899lhRDuBb3/pWUe7II48syv32t78tHvvtb397Ua70733LLbcUj93qCtdbrVq1qniZncYZMUmSJEmqmDNikiRJbRYRJwGXZubciDgS+AIwCCwB3pmZW+qsT1L9bMQ60NSpU1tmPvCBD7TMfPjDH25HOZXZb7/9Wmauu+66lpkZM2aMuZajjjpqzMuQJO2aIuJ9wHnAk82XLgcuzsybI+KzwDnAgrrqk9QZPDRRkiSpvZYB5w55fhzwg+bjhcCZlVckqePYiEmSJLVRZt4ADL2ixoTM3HoH87XA9OqrktRpbMQkSZLG19DzwfqA1XUVIqlz2IhJkiSNrzsjYm7z8TzghzXWIqlDeLEOSZKk8fVe4OqImALcC1xfcz2SOoCNmCRJUptl5gPAyc3HS4HTay1IUsexEZMkSVKRp556qij36KOPFi/zWc96VlHuvvvuK8ode+yxxWM/+OCDRblDDz20KLf33nsX5TZt2lSUA3jBC15QlDvxxBOLcmeddVbx2P39/UW5gYGBotyaNWuKx/7ud79blNuZv3en8RwxSZIkSaqYM2IdaMOGDS0zn/rUpyqopFovfelLW2Ze85rXtGWspUuXjvj+TTfd1JZxJEmSpOE4IyZJkiRJFbMRkyRJkqSK2YhJkiRJUsVsxCRJkiSpYjZikiRJklQxr5ooqWdExG7ANcBhwO7ARzPzm7UWJUmSNAxnxCT1kjcCKzPzVGAecEXN9UiSJA3LGbEOtGXLlpaZxx57rIJKqrV27drKxrr44otHfH/hwoUVVaI2+xpw/ZDnA3UVIkm7sokTy/f1z549uyj38MMPF+VuvfXW4rGf85znFOU2btxYlCv9vSdNmlSUAzjrrLOKcuvWrSvKzZkzp3jsO+64oyh31113FeV25j6tz3ve84py++yzT/EyO42NmKSekZnrACKij0ZDNnLHLUmSVBMPTZTUUyLiYOD7wLWZ+ZW665EkSRqOM2KSekZE7A8sAt6Vmd+rux5JkqQdsRGT1Es+BOwDXBIRlzRfm5eZG2qsSZIk6RlsxCT1jMy8ELiw7jokSZJa8RwxSZIkSaqYjZgkSZIkVcxGTJIkSZIq5jli6hgnnHBCZWOV3DRbkiRJGi/OiEmSJElSxYpmxCLiJODSzJwbES8GbgR+2Xz7qsz86ngVKEmSpO6yM0eePPDAA0W5adOmFeWmTp1aPPaTTz5ZlDvggAOKcuvXry8eu1RfX19R7sEHHyzK3XvvvcVj77nnnkW5e+65pyhX+rsADA4OFuVmzpxZvMxO07IRi4j3AecBW/+lvhi4PDM/MZ6FSZIkSVKvKjk0cRlw7pDnxwFnR8QtEfH5iChvbSVJkiRJrRuxzLwBeHrISz8BLsrM04DlwEfGqTZJkiRJ6kmjuVjHgsxcvPUxcGwb65EkSZKknjeaRuw7EXFi8/EZwOKRwpIkSZKkbY3mPmJ/DlwREZuAR4EL2luSJEmSJPW2okYsMx8ATm4+/hlwyjjWpB40Y8aMlpkPfvCDbRmr5BKqCxYsaMtYkiRJ0mh4Q2dJkiRJqpiNmCRJkiRVbDTniEmSJEk7NDg4WJzdtGlTUW7ixLL5g9IcwJYtW4pykyeXbTKvXbu2KLd8+fKiHMC+++5blPu93/u9oty0adOKx77vvvuKcrNnzy7K/fSnPy0e+9RTTy3K7czv02mcEZMkSZKkitmISZIkSVLFbMQkSZIkqWKeIyZpl/OrZ/8xswcH6i5j1K749dvqLqE9Jqypu4Ix+6/vvbruEsbu/sPrrmBsHlsB599YdxWStNOcEZMkSZKkijkjpkq88pWvbJmZOnVqW8b62Mc+1pblSJIkSePFGTFJkiRJqpiNmCRJkiRVzEZMkiRJkirmOWKSJEnSCLZs2VKUe+ihh4pyRx11VPHYmzZtKsq96U1vKsrdfPPNxWOvWVN2dds777yzKDdz5szisffcc8/ibLdyRkySJEmSKmYjJkmSJEkV89BESZKkNouIk4BLM3NuRLwYuBH4ZfPtqzLzq/VVJ6kT2IhJkiS1UUS8DzgPeLL50ouByzPzE/VVJanT2IipEnvvvXdblrNkyZKWmW9+85ttGUuSpFFaBpwLXNt8fhwQEXEOjVmxd2fm2rqKk9QZPEdMkiSpjTLzBuDpIS/9BLgoM08DlgMfqaUwSR3FRkySJGl8LcjMxVsfA8fWWYykzmAjJkmSNL6+ExEnNh+fASweKSxp1+A5YpIkSePrz4ErImIT8ChwQc31SOoANmKSJEltlpkPACc3H/8MOKXWgiR1HBsxSZIkaQRPPvlk6xAwZcqUotxBBx1UPHbpMkuuLA07dyXr66+/vig3Y8aMotyBBx5YPPb06dOLs93Kc8QkSZIkqWI2YpIkSZJUMQ9N1JiVTB2/613vastYixYtapkpPXxAkiRJqoszYpIkSZJUMWfEJPWUiJgEXA0EsBk4PzOX1VuVJEnStpwRk9RrXgOQmS8F/gK4vN5yJEmSnslGTFJPycyv87ubpR4KPFZjOZIkScPy0ERJPSczByLii8AfAa+rux5JkqTtOSMmqSdl5puB5wBXR8TUuuuRJEkayhkxST0lIs4DZmfmx4H1wBYaF+2QJGlUfvOb3xTlBgYGinJr164tHvuQQw4pym3atKkoV1ojwLp164pykyZNKsodccQRxWPvCmzENGbnnntuy8xzn/vclpnVq1e3zFx11VVFNWmX9s/A30fELcBuwLszc2PNNUmSJG3DRkxST8nMJ4E/qbsOSZKkkYzYiEXEbsA1wGHA7sBHgXuALwCDwBLgnZm5ZVyrlCRJkqQe0upiHW8EVmbmqcA84Aoa9+S5uPnaBOCc8S1RkiRJknpLq0bsa8AlQ54PAMcBP2g+XwicOQ51SZIkSVLPGvHQxMxcBxARfcD1wMXAZZk52IysBaaPa4WSJEmS1GNa3kcsIg4Gvg9cm5lfoXEp6K36gNaXupMkSZIk/acRG7GI2B9YBLw/M69pvnxnRMxtPp4H/HD8ypMkSZKk3tPq8vUfAvYBLomIreeKXQh8KiKmAPfSOGRRkiRJklSo1TliF9JovLZ3+viUo240f/78tizn5z//ecvM8uXL2zKWJEnS6tVlZ9j09/cX5WbMmFGUmzlzZlEOYPbs2UW5ZcuWFeVWrVpVPPaWLWV3qCqtce+99y4ee1fQ8hwxSZIkSVJ72YhJkiRJUsVsxCRJkiSpYjZikiRJklQxGzFJkiRJqpiNmCRJkiRVzEZMkiRJkipmIyZJkiRJFRvxhs4SwGWXXTbi+69+9avbMs43vvGNtixHkiRJ6nTOiEmSJElSxZwRkyRJUs8YHBwszq5cubIot27duqLczJkzi3IzZswoygGsWrWqKDd16tSi3MKFC4vHLl3moYceWpSbONE5oKH8NCRJkiSpYs6ISdrlHP7w+xkY6Ku7jFH71wkfqLuEtrhx8Fd1lzBmr/7Lm+ouYcwmHFQ+e9CR+ifUXYEkjYozYpIkSZJUMRsxSZIkSaqYjZgkSZIkVcxGTJIkSZIq5sU6dnHTpk1rmWnHDZtvu+22lpkrr7xyzONIkiRJ3cAZMUmSJEmqmI2YJEmSJFXMQxMlSZLUMzZu3Ficvfvuu4tyRxxxRFFu9erVRbljjz22KAdw001l9yucOLFsfuXxxx8vHnu33XYryh1wwAHFy9TvOCMmSZIkSRVzRkySJKlNImI34BrgMGB34KPAPcAXgEFgCfDOzNxSU4mSOoQzYpIkSe3zRmBlZp4KzAOuAC4HLm6+NgE4p8b6JHUIGzFJkqT2+RpwyZDnA8BxwA+azxcCZ1ZdlKTO46GJkiRJbZKZ6wAiog+4HrgYuCwzB5uRtcD0msqT1EFsxHZxRx11VMvMnDlzxjzOQw891DLz9NNPj3kcSZLqFhEHAwuAKzPzKxHx10Pe7gPKLq0nqad5aKIkSVKbRMT+wCLg/Zl5TfPlOyNibvPxPOCHddQmqbM4IyZJktQ+HwL2AS6JiK3nil0IfCoipgD30jhkUdIuzkZMkiSpTTLzQhqN1/ZOr7oWSZ3NRkySJEk9Y/Xq9p+CN2XKlKJcybn3ANOmTSsee/PmzUW5X//610W5nfl8TjnllKJc6eejbXmOmCRJkiRVzEZMkiRJkirmoYmSek5E7AcsBs7KzPvqrkeSJGl7zohJ6ikRsRvwt8CGumuRJEnaEWfEdnFnn3123SVI7XYZ8Fngg3UXIkmStCMjNmLNPcvXAIcBuwMfBVYANwK/bMauysyvjmONklQkIt4CPJGZ34kIGzFJktSxWs2IvRFYmZnnRcQM4E7gL4HLM/MT416dJO2ctwKDEXEmcAzwDxHxh5n5aM11SZIkbaNVI/Y1tr37+wBwHBARcQ6NWbF3Z+bacapPkopl5mlbH0fEzcA7bMIkSVInGvFiHZm5LjPXRkQfjYbsYuAnwEXNDZ7lwEfGv0xJkiRJ6h0tL9YREQcDC4ArM/MrEbF3Zm69JfcC4NPjWaAkjUZmzq27BklS9QYHB4uz++67b1HuiSeeKMotXbq0KLdu3bqiHMD9999flFu+fHlR7rDDDise+6CDDirOaueNOCMWEfsDi4D3Z+Y1zZe/ExEnNh+fQeNePZIkSZKkQq1mxD4E7ANcEhGXNF97D/DJiNgEPApcMI71SZIkSVLPGbERy8wLgQuHeeuU8SlHVfv4xz/eMjN//vwR31+1alXLZXz60x7BKkmSJG014qGJkiRJkqT2sxGTJEmSpIrZiEmSJElSxWzEJEmSJKliNmKSJEmSVDEbMUmSJEmqmI2YJEmSJFWs1Q2dJUmSpK4xODhYnD355JOLcvfcc09R7oknnijKffKTnyzKAcyaNaso97znPa8od8cdd7R9bI2Ojdgubv369S0zRx99dAWVSJIkSbsOD02UJEmSpIrZiEmSJElSxWzEJEmSJKliNmKSJEmSVDEbMUmSJEmqmI2YJEmSJFXMRkySJEmSKjZe9xGbBDB5srcpk3rFkO/zpDrrGKPmuunJuusYk5U9cgvILSsG6i5hzFas6/6/xeT+FXWXMCaT1z669WE3r5ugWX9/f3/ddXS9NWvWFGenTJlSlFu3bl1R7qmnnirKTZxYPhdSWuPGjRuLcqU1AqxataooN2HChOJl7kqGfJ+HXT9N2Jm7j5eKiJcBP2z7giV1glMz89a6ixgN101ST+vadRO4fpJ63LDrp/HalfdT4FTgEWDzOI0hqVqTgANpfL+7lesmqff0wroJXD9JvWjE9dO4zIhJkiRJknbMi3VIkiRJUsXG/SzjiJgIXAm8CHgKeHtm3j/e445FRNwJbD277leZeX6d9exIRJwEXJqZcyPiSOALwCCwBHhnZm6ps77tbVfvi4EbgV82374qM79aX3W/ExG7AdcAhwG7A2ULJWoAAAQDSURBVB8F7qFDP98d1LuCDv18e1U3rut2ZOh3te5aRmO470RmfrPWonZSREwCrgaCxmFq52fmsnqrGp2I2A9YDJyVmffVXU836KX1yVbdsm01km7b7hpJt2yTtdJt22zbq2JGbD6wR2a+BPgA8IkKxhy1iNgDIDPnNv/XkSuKiHgf8Dlgj+ZLlwMXZ+apwATgnLpqG84w9b4YuHzI59xJX/g3Aiubn+U84Ao6+/Mdrt5O/nx7VVet63ZkmO9qNxruO9FtXgOQmS8F/oLGOqjrNDeS/hbYUHctXaYn1idbdcu21Ui6bbtrJF22TdZKt22zbaOKRuxlwLcBMvN24PgKxhyLFwF7RsSiiLgpIk6uu6AdWAacO+T5ccAPmo8XAmdWXtHIhqv37Ii4JSI+HxF9NdU1nK8Blwx5PkBnf747qrdTP99e1W3ruh3Z/rvajYb7TnSVzPw6cEHz6aHAYzWWMxaXAZ8FHq67kC7TK+uTrbpl22ok3bbdNZJu2iZrpdu22bZRRSM2jd9NRQNsjohOvvHKehr/4fh94B3Alzux3sy8AXh6yEsTMnPrlVfWAtOrr2rHhqn3J8BFmXkasBz4SC2FDSMz12Xm2uaK6HrgYjr4891BvR37+fawblvXDWuY72rX2cF3outk5kBEfBH4NI3fo6tExFuAJzLzO3XX0oV6Yn0yRFdsW42k27a7RtJN22StdNs22/aqaMTWAEM764mZ2cl7J5cCX8rMwcxcCqykcdnJTjf02Nc+YHVdhRRakJmLtz4Gjq2zmO1FxMHA94FrM/MrdPjnO0y9Hf359qhuW9f1tGG+E10pM98MPAe4OiKm1l3PTnorcFZE3AwcA/xDRBxQb0ldo9fWJ926bTWSjt4u2Eldvc3QbdtsQ1XRiN0GvAqgORV9VwVjjsVbaR6LHRHPprFX6pFaKypzZ0TMbT6eR+ffFPI7EXFi8/EZNE7k7ggRsT+wCHh/Zl7TfLljP98d1Nuxn28P67Z1Xc/awXeiq0TEeRHxwebT9TQ2LLrq3lKZeVpmnt686Mt/AG/KzEdrLqtb9Nr6pFu3rUbSsdsFo9C12wzdts22vSqmhRfQ2CP2IxonzHX6CZqfB74QEbfSuNrKW7tkL9R7aewxnQLcS+cfxvLnwBURsQl4lN+dC9EJPgTsA1wSEVuPO74Q+FSHfr7D1fse4JMd+vn2qm5b1/Wy4b4T8zKzmy4Y8c/A30fELcBuwLszc2PNNak6vbY+6dZtq5F023bXSDp5m6yVbttm24Y3dJYkSZKkinlDZ0mSJEmqmI2YJEmSJFXMRkySJEmSKmYjJkmSJEkVsxGTJEmSpIrZiEmSJElSxWzEJEmSJKliNmKSJEmSVLH/D9HTts6HqVCjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x2160 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,30))\n",
    "plt.subplot(131)\n",
    "plt.title('Input')\n",
    "plt.imshow(image,'gray')\n",
    "plt.subplot(132)\n",
    "plt.title('Weight')\n",
    "plt.imshow(weight[0,0,:,:],'jet')\n",
    "plt.subplot(133)\n",
    "plt.title('Output')\n",
    "plt.imshow(output_arr[0,0,:,:],'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "- F.max_pool2d\n",
    "    - stride\n",
    "    - kernel_size\n",
    "- torch.nn.MaxPool2d 도 많이 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 12, 12])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = F.max_pool2d(output,2,2)\n",
    "pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MaxPool Layer는 weight가 없기 때문에 바로 numpy()변환 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 12, 12)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_arr = pool.numpy()\n",
    "pool_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "plt.subplot(121)\n",
    "plt.title('Input')\n",
    "plt.imshow(image,'gray')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Output')\n",
    "plt.imshow(pool_arr[0,0,:,:],'gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear\n",
    "- 1d만 가능 .view()를 통해 1D로 펼쳐줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.from_numpy(image)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = image.view(1,28*28)\n",
    "flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = nn.Linear(784,10)(flatten)\n",
    "lin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1946,  0.3295, -0.1909, -0.4465,  0.2830, -0.5182,  0.3691,  0.0096,\n",
       "         -0.7853, -0.3220]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADnCAYAAAApSCziAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAASdklEQVR4nO3df6xkZX3H8fe9M/sDZRdBRUyQwhb91rbRxqARBLUBStFa/cfEYBNEJEK1Kqax+IOkVo0tFk1pi1YCKVSaxhKpQAu2ojSwSFZbbbEtX7MtxhLlh/xcCrt3Z+7tH2cujHfvzjnMnTlz7p73K5nk3jnPnee5S/jss9/znOeZW1paQpI0e/OzHoAkqWAgS1JDGMiS1BAGsiQ1RHfWA5CkOkTEYcDWis0fy8yHpjme1cy5ykLSgS4iDtvY7z+40OlU/ZGHgWPrDmVnyJLaYOtCp8MpP/oRz+r1RjZ8otvl60cddSjFbNpAlqRp2NrrcXBJIM8yFA1kSa2xGTiopM3ouJ4uA1lSa3SBDRXazIqBLKk1OpSHXuXbflNgIEtqjQ2Uz5DLrk+TgSypNZwhS1JDOEOWpIaosspidx0D2Q8DWVJruMpCkhrCGrIkNYQ1ZElqCGfIktQQVW7qba5jIPthIEtqDUsWktQQliwkqSFc9iZJDdGlPPQMZEmqgTNkSWoIV1lIUkNs6FZYZTHDVDSQJbVGp1NhlcUMl1kYyJJao9upUEM2kCVp+rod6M6VtJmvZyyr9j27riWpXt1NsGGxpI2BLEk16ABlgVsyg54mA1lSe3SBpZI2BrIk1WCWG1VUYCBLag8DWZIaokN5SWIJWHHjLyLmgUuBlwN7gHdl5s6h6+cDbxt8+w+Z+fFxhjfD+4mSVLONwKaS18ZVf/ItwObMPB64ALh4+UJEbAPeDpwAHA/8WkS8bJzhGciS2qNb8bWvE4GbADLzDuC4oWv/C/x6ZvYzc5Hi2ZPd4w5PktqhQ3kdub/qu1uBR4dbRUQ3M3uZuRf4aUTMAZ8BvpuZPxhneAaypPaoEsirewzYMvT9fGb2lr+JiM3AFcAu4LfHHZ6BLKk9qpzhtLrtwJuAL0fEq4E7ly8MZsZfBb6RmX+0luEZyJLao8qRIau7Fjg1Im6nWKdxVkR8ENhJEfOvAzZFxOmD9h/OzG+NMzxJaoeNlG/3tspSh8HNunNXvH3X0NcT2dfeQJbUHlVKFiWbD02TgSypPaqULAxkSapBlVUWblAvSTWoUrJYfR1yLQxkSe2x/Oj0KGXbc06RgSypParUkD11WpJqUKVkYQ1ZkmrgDFmSGmKe8hmwh5xKUg2cIUtSQ1RZZdEruT5FBrKk9vCmniQ1hCULSWoIZ8iS1BDuZSFJDWHJQpIaosoqiz11DGR1BrKk9rCGLEkNYclCkhrCR6clqSGcIUtSQ2yi/Hzospt+U2QgS2oPSxaS1BCWLCSpIVz2JkkN4aPTktQQliwkqSGqPDq9sY6BrM5AltQe1pAlqSHGLFlExDxwKfByiu2H3pWZO4eunwO8m+IAqE9m5g3jDG+GK+4kqWbLM+RRr9VnyG8BNmfm8cAFwMXLFyLiCOB9wGuA04BPR8RYj5cYyJLao1Pxta8TgZsAMvMO4Liha68Ctmfmnsx8FNgJvGyc4RnIktpj/BnyVuDRoe/7EdHdz7VdwCHjDM8asqT2GH+VxWPAlqHv5zOzt59rW4BHxhmegSypPcZfh7wdeBPw5Yh4NXDn0LUdwKciYjNF3L8U+P64w5Okdhh/2du1wKkRcTswB5wVER8EdmbmdRFxCXArRRn4o5m5e5zhGciS2mPMGXJmLgLnrnj7rqHrlwGXrXF0BrKk9ljqFK+yNrNiIEtqjb2bYKFkg/q9blAvSdPXn5+n1xm92rc/P7vVwAaypNbod7v0S1Kv351dLBrIklqjPz9PvzO6SOwMWZJqsEiHfoU2s2IgS2qNHvP0KrSZFQNZUmvsZRMLLJa0MZAlaer6zNNnrqTN6OvTZCBLao2ihrxU0sZAlqSpq1ZDnh0DWVJrLNKtsMpidgxkSa2xwAYWSkoSCywxq1g2kCW1Rp8OvdKbegayJE1dnw79kmVtfRaBvfUMaAUDWVJrLFYIZFdZSFINinXIJXtZ1DSW1RjIklqjKFkcYIEcEQcBXwIOpzjy+szMfGBFm+uA51IUY57MzNPXOFZJWpMFNrKnJPYWZrgSedwZ8nnAnZn5+xHxNuBjwPtXtDkW+KXMHP1YjCTVZLHCDHmx5Em+aRo3kE8ELhp8fSNw4fDFiHgB8Bzg+oh4DvCHmXnD0PVNwCuBnzDbfyFIar4O8ELg25m5Zy0fVK2GPLtHQ0oDOSLOBs5f8fZ9wKODr3cBh6y4vhG4GPgT4DBge0TsyMz7B9dfSXFktiRVdRJw21o+oFiHvI4DOTMvBy4ffi8ivgJsGXy7BXhkxY/dC3whM3vA/RHxXSCA5UD+CcDVB/+II+anX6/5u+9NvYun/Pjud9bSz2duurC80YT803nH1NbXqWfeXVtf77+yvt/rA39fTz/HvHFl5XB6jr371Fr6Wbr3QZbe/nEY5MZa9OnSL4m9ss2HpmncksV24A3ADuB09p3tngK8F3hjRBwM/DLwX0PX+wBHzPc4sjP9QH5OjTX6XUc+q5Z+eoceWUs/AIf36vsD7B1U3+91cI2/15GH19NPr3dwPR0Bc0c+v7a+BhG55vJmtZLF7Kqo4wby54ErI+I2YAE4AyAiLgKuycwbI+K0iLiD4hnEj2TmTycyYkka0wIb2MPGkjbrbIacmU8Ab13l/Q8Nff2BNYxLkiZusULJYnEdzpAlad2p9mCIh5xK0tRVqyF7pp4kTV21B0OcIUvS1BWPTm8qadPgdciSdKCYZA254p4+n6F4srkLfDEzLxv1mWMVSyJiPiK+EBHfiohbIuLYFdfPiYjvRMQdEfEb4/QhSZO2XEMe/aoci8t7+pwEXEWxp89TIuJXgWMz83iKUP69iDh01AeOW71+C7B50NEFFI9JLw/iCOB9wGuA04BPD/aukKSZWn50etTrGayyOBG4afD1jRQPxA37FrD86O4SxZ4cI48iWcvmQjcBZOYdEXHc0LVXAdsHm4DsiYidwMuAb4/ZlyRNRDEDLnt0et9AHmdPn8zcDeyOiA3AlRQli8dH9T1uIG8dGghAPyK6g70rVl5bbfMhSarduKssxtzTh0GJ4hrglsz8dNn4xg3kx4YGAjA/COPVrq06UEmq2wIb2FD66PRC1Y8buafP4KbfzcDFmXl1lQ9cy+ZCbwK+HBGvBu4curYD+FREbAY2AS8Fvj9mP5I0MdW236xcQx65pw/FfbRtwDkRcc7gZ87KzP1uaThuIF8LnBoRtwNzwFkR8UFgZ2ZeFxGXUPxtMQ98dFBLkaSZGreGvJoKe/rsAD73TMY37uZCi8C5K96+a+j6ZcDI9XaSVDef1JOkhnBzIUlqiB7zpTXknpsLSdL07WUjnZK9LPaWrMKYJgNZUmtYQ5akhrCGLEkN0WOezoFWQ46IeeBS4OXAHuBdmblz6PolFIuidw3eenNmPrrPB0lSjaqdqTe7eeq4PT+129vgSb2LgTcPXX8FcNqIk6Y7APcu1vOLP1Ljn++ue56opZ/uw/fU0g/A/d36/gC7T9b3ez1e4+91z/319NPtjty7ZqKW7nmgvNEk+rn3weUv11xL2MsGKLlpV7SZjYnv9jaYPb8Y+GJEvAC4PDOvWPHzLwR4++NHjdn9M7Stnm4AOPmWWrrZRj39ALx7W31/gNtuPbm2vq6v8fe6/nfq6Wfbtuvr6QhYPLm+vgZeCPz3Wj6gR4e50pLF+qshj9rt7dnAnwKfpfgb7ZsR8Z3M/Peh9t8GTgJ+AjM8c1vSetChCOM1b+Hbp8P8hB6dnoZp7Pb2BPAng+e8iYhvUNSanwrkwV7Jt43Zt6T2WdPMeFnTl72Neztxeds5Vtnt7SXAbRHRGWzMfCLwr2sapSRNwISPcJq4ae32djVwB8VxJVdl5n9MZriSNL5idnyArUOusNvbRcBFaxjXzyhbZrdeDf4FcQVwNMXe0Z/MzOtmOqgJiYjDgX8BTs3Mu8rarwcR8WHgNylu0186OEViXRs6Xuhoivs55xwo/71Ws1Dh0en+DB+dnt3c/JnZ76Gq69xvAQ8OTq09HfizGY9nIgb/k/8F8OSsxzIpEfF64ASK9fWvA1400wFNzhuAbmaeAPwB8KkZj2eqFkvLFZ11WUOu288sswOOG9183fhb4MKh73v7a7jO/DHwBeDHsx7IBJ1Gca/kWuB64IbZDmdifgB0B/8K3UrJqcjrXdNryOslkFddZjerwUxKZj6embsiYgvFkS8fm/WY1ioi3gE8kJlfm/VYJux5FBOBt1KU666OiLnZDmkiHqcoV9xFcajEJTMdzZQtH+E06jXLGvJ6CeRRy+zWtYh4EfBN4K8y869nPZ4JeCfFDd9bgF8BroqII2Y7pIl4EPhaZi5kZgK7gefPeEyTcD7F7/USins0Vw7OwzwgLR/hNPq1zm7qzcCoQ1XXrcGTjP8IvDczb571eCYhM1+7/PUglM/NzHtnN6KJuQ14f0R8luIhhWdThPR69zBPlykeAjYwgUeUm2qxwiqLWf766yWQ91lmN+PxTMpHgEOBCyNiuZZ8emYeMDfDDhSZeUNEvJbi4Mp54D2ZeSA8Zfo54IqIuJVi9chHMvP/ZjymqdlTYS8L2FCyDmN65paWlmbUtSTVIyKOBu5+8uYrWDryBSPbzt1zHwed/E6AYzLzh9Mf3dPWywxZktaszzxLJSWJuXX4pJ4krTuLFdYZz1tDlqTp6y91WFwcHbhLSwayJE3dwp6N9HePvmXX2eOp05I0df3ePP1eyQy4Zw1ZkqZusd8pDeS5viULSZq63t4Ovb0lgVt2fYoMZEmtsbjYYbFfcup0yU2/aTKQJbVHr1O8ytpUEBEHAV8CDgd2AWdm5j5HcUfEs4DbgQsy86ZRn7leNheSpLXb04Hd3dGvPZVnyOcBdw72M7+K/e/W+OdApUeiDWRJ7dGn2HV81Kv6DiVP7dMO3AicsrJBRPwuxez436p8oCULSe2xHLplbVaIiLMptioddh9P79O+Czhkxc+cDLw4M98dEa+pMjwDWVJ7LM+Qy9qsMDg/8WfOUIyIr/D0Pu1bgEdW/NjZwM8NtqH9BeAVEXFvZn5vf10byJLaYy/lh1RVP8RqO8WZhDsozsS8dfhiZp6x/HVE/CXwN6PCGAxkSW2yQHFufVmbaj5PccLKbYOfOgMgIi4CrsnMHc90eAaypPYYs2Sxmsx8guKMxZXvf2iV995R5TMNZEntMeZNvboYyJLaY4Iz5GkwkCW1hzNkSWoIZ8iS1BB7gN0V2syIgSypPSxZSFJDWLKQpIZwhixJDeEMWZIawhmyJDXEbmBDhTYzYiBLao9FyksSi3UMZHUGsqT2sGQhSQ3hTT1JaghnyJLUEHuAskOlfXRakmpgyUKSGsKShSQ1RI/yQ0wNZEmqQZ/ykoQlC0mqgTVkSWqI3ZQ/ibdQx0BWZyBLag9LFpLUEJYsJKkhesBchTYzYiBLao8qYWsgS1IN+pTPkC1ZSFIN9mANWZIaoUf5sjc3qJekGvSBpZI2FQM5Ig4CvgQcDuwCzszMB1a0eQdwHsUec1/NzE+M+sz5al1L0gFgednbqFf1ksV5wJ2ZeRJwFfCx4YsR8fODNq8HXgVsjIiRJ/oZyJLaoyyMq+wG97QTgZsGX98InLLi+inAd4ArgX8GtmfmyK2NLFlIao+qm8+vmMdGxNnA+Sta3Qc8Ovh6F3DIiuvPA14LnAAcBGyPiFdm5iP769ZAltQeVWrIc+wTyJl5OXD58HsR8RVgy+DbLcDKoH0QuCUzdwG7IuI/gZcAO/bXtYEsqT16VAvkarYDb6AI2NOBW1e5/p6I2ExxU+8XgZ2jPtBAltQeVZa9Vb+z9nngyoi4jWKPuDMAIuIi4JrM3BERl1ME8xzwicx8aNQHzi0tlf11IUnrW0QcDdz9Pw/eTG/xyJFtu/P3sO25JwMck5k/nP7ohvquszNJmqkq22+WnUo9RQaypPbYTfmythmmooEsqT2qzJCr39SbOANZUnssUb7KYoa31XxST5IawkCWpIYwkCWpIawhS2qR3cCTFdrMhoEsqUV6wMgN15jloXoGsqQWWd4QuazNbBjIklpkL+Uz5LLr02MgS2oRSxaS1BDe1JOkhqhyRpMzZEmqgSULSWoIV1lIUkO4ykKSGsIZsiQ1hKssJKkhLFlIUkNYspCkhnDZmyQ1hCULSWoISxaS1BCuspCkhrBkIUkNYclCkhrCVRaS1BBuvylJjdDtPkTZTbtu94l6BrNa3zPrWZLq8xjw8FFHff3Qiu0fHvxMreaWlpbq7lOSahcRhwFbKzZ/LDMfmuZ4VmMgS1JDzM96AJKkgoEsSQ1hIEtSQxjIktQQ/w/nwZvZA3wXzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(lin.detach().numpy(),'jet')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    flatten = image.view(1,28*28)\n",
    "    lin = nn.Linear(784,10)(flatten)\n",
    "    softmax = F.softmax(lin,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1317, 0.0565, 0.0392, 0.1468, 0.0927, 0.0752, 0.1252, 0.0749, 0.1000,\n",
       "         0.1578]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000001"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(softmax.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F.relu\n",
    "- ReLU 함수를 적용하는 레이어\n",
    "- nn.ReLU로도 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 28, 28])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(4,3,28,28).to(device)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20, 24, 24])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Conv2d(3,20,5,1).to(device)\n",
    "output = F.relu(layer(inputs))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "- import torch.optim as optim\n",
    "- model의 파라미터를 업데이트\n",
    "- 예시)\n",
    "- optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "- optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "- .zero_grad()로 초기화\n",
    "- .step()으로 업데이트"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
